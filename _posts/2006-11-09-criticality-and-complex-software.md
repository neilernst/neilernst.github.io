---

date: 2006-11-09 21:02:40+00:00
layout: post
title: Criticality and complex software
---

A software system is a human-created artifact. And yet, even though humans are in control at every stage in the process, these systems often exhibit unanticipated effects. Most attention is focused on undesirable effects, such as the [Ariane 5 failure](http://en.wikipedia.org/wiki/Ariane_5_Flight_501). Presumably there are also unanticipated and unexpected _positive_ effects that we aren't told of, for the obvious reason that things work as expected, and there is no reason to question why.

Since software is human-controlled, there should be no obvious reason to compare it to natural systems like gene networks or chemical reactions. However, as Stuart Kauffman notes in ["At Home in The Universe"](http://www.amazon.com/At-Home-Universe-Self-Organization-Complexity/dp/0195095995/ref=ed_oe_h/104-7655899-5779117?ie=UTF8), humans are restricted to guessing about the future. As such, we cannot anticipate all potential scenarios. This makes human-created artifacts subject to the same randomness that many natural processes are. Consider the biological notion of 'fitness landscape'. For a given fitness landscape there is a global maximum that describes the best adapted genotype. Clearly, we should strive to have all software reach this global maximum. But, as I have mentioned, we cannot control all the variables, since we can't anticipate all occurences and changes in the environment. This means we can't know ahead of time what the environment will be like when we build our software.  If we knew, then we would clearly strive to build to this global maximum. Instead, we attempt to build to some pre-specified local maximum, that for us is best-adapted to our environment (see Jackson). However, even this is unlikely. For example, we may abandon certain features as deadline pressures mount. One way of looking at this is that we are changing the environment that we are targeting (abandoning requirements of the environment).

How might software mimic dynamical systems, like biological evolution? Evolution is essentially a process of striving towards these peaks in a fitness landscape. Evolving software should seek to improve its adaptation to a given set of environmental constraints (fitness pressures). The landscape shifts as new environmental constraints and conditions become known, so our software has to adapt itself (reproduce? variation? genetic drift? somehow adapt). Successful software will move to a new local maximum on the new fitness landscape.  Constantly shifting environments might reflect an unstable ecology, in which maxima are impossible to find (rugged). Other landscapes might be extremely stable. For example, a long-running satellite might have very few environmental changes.  We can use this landscape metaphor to model why different software seems to have different requirements.

I want to digress for a minute to discuss criticality. In small systems, we might not see any complexity effects. For example, code to post blog entries might seem easy to get mostly right (to hit a good local maximum). Why all the fuss? My contention is that at some threshold, which will change depending on what the environment is, software shifts from simple to complex. This notion is similar to laminar vs. turbulent flow in fluids. At some threshold, what was a simple-to-model system becomes nasty and impossible to predict. We need simulations and approximation algorithms to understand it. Well, I think the same is true of certain software systems. They may cross this threshold and have unpredictable effects - and this in a system in which we know all the inputs and all the outputs.  Even with human control, in other words, we cannot truly control the outcomes.
