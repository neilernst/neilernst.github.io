---

date: 2005-11-17 03:16:12+00:00
title: Peter Norvig talks at UofT
---

The departmental colloquium today was given by [Peter Norvig](http://www.norvig.com/), aka Russell Norvig, from Google. He talked about Google's approach to making information accessible and useful to people. I was going to transcribe parts of what he said but Alvin Chin has [already done that](http://www.the-gadgetman.com/blog/2005/11/peter-norvig-talk-from-google-today.html), I see.

Some of my thoughts:

  
  * The fact that the size of a dataset has more bearing on the accuracy of a machine learning algorithm than the actual algorithm design is an interesting point. However, one question they haven't proven (nor can they) is whether they just haven't found that 'killer' algorithm. Most researchers don't have the Google dataset to work with, which I argue changes everything.
  
  * The notion of statistical learning is fine, so long as the user is looking for the statistically likely result, e.g., Macdonald's Restaurants, the hamburger chain, instead of Macdonald's Hamburgers, the Missouri cattle farmer. This effect can also be seen in the results returned for the ego-Google: Neil Ernst returns a number of my pages, but I'm sure there are many others out there who are equally interesting to some group of people. How can Google retrieve pages for those searches with machine learning?
  
  * That is part of the answer that Norvig gave to the social searching question. He mentions that most searches are unbelievably strange, most of them coming in the right side of the long tail. Google doesn't do a great job of serving this population, I don't think (Yahoo's "My Web" might do better, but I haven't tried it). Sure, I get 2 million links for "Neil Ernst" but why do I care about more than the first two pages? It's true that for the majority of things I search on, I get what I want. But maybe that's more a case of me lowering expectations than Google being exactly what I need (and I suspect Norvig would probably agree).
  
  * Finally, although Norvig claims that Google's approach -- AI in the Middle -- is intended to bridge the gap between knowledge engineering and machine learning, I'm not sure they're all addressing the same problem. To my mind, AI is such a large topic area that each of the approaches is good at one problem or another. For example, knowledge engineering might be quite appropriate in complex, quick-changing environments like medicine or military applications.
At any rate, I found the talk quite interesting and thought-provoking, which after all is the point. Peter Norvig has had quite the career and gave a great talk.  


  

