[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching and Materials",
    "section": "",
    "text": "Dates are planned future offerings. Where future = “as of when I last updated this page (Jun 22)”.\n\n\n\nSENG 350, Software Architecture. Fall 22\nSENG 330, OO Design.\nSENG 321, Requirements Eng. Spring 23\nCSC 497 - Interdisciplinary Project\n\nThis is the project capstone for students in any combined program. I advise students in Geomatics. This course is scheduled by completing the Directed Studies (Pro Forma) form available here. The project must combine elements of Geography (landscapes, geomorphology, human geography, climate change, etc. etc.) and Computer Science (software development, algorithms, networking, visualization, etc. etc.).\nThe format of the project is decided with the project advisor, but must include a final report and final public presentation (usually at a group meeting or department seminar). I strongly recommend weekly reports as a deliverable. The project should take 10-15 hours per week to complete. You cannot use content from other courses for this project, but building on top of those results is fine.\nPast projects have included comparing ML algorithms on remote sensing data, predicting urban growth, and mapping plankton blooms.\nThe course needs to have an advisor; students can find one on their own, or work with me on a topic. A good approach is to find a professor whose classes you have enjoyed and ask them directly. Most profs are more than happy to advise an independent research project that aligns with their ongoing research.\nThis is (supposed to be) a fun course! You get to work on ideas and problems that are interesting to you.\nFailing is possible, and usually happens when students do not keep up with the work.\n\n\n\n\n\n\nSENG 480X/CSC 586X, Data Science for SE. Fall 22\nSENG 480X/CSC 586X, Documenting and Understanding Software Systems."
  },
  {
    "objectID": "teaching.html#undergrad-courses",
    "href": "teaching.html#undergrad-courses",
    "title": "Teaching and Materials",
    "section": "",
    "text": "SENG 350, Software Architecture. Fall 22\nSENG 330, OO Design.\nSENG 321, Requirements Eng. Spring 23\nCSC 497 - Interdisciplinary Project\n\nThis is the project capstone for students in any combined program. I advise students in Geomatics. This course is scheduled by completing the Directed Studies (Pro Forma) form available here. The project must combine elements of Geography (landscapes, geomorphology, human geography, climate change, etc. etc.) and Computer Science (software development, algorithms, networking, visualization, etc. etc.).\nThe format of the project is decided with the project advisor, but must include a final report and final public presentation (usually at a group meeting or department seminar). I strongly recommend weekly reports as a deliverable. The project should take 10-15 hours per week to complete. You cannot use content from other courses for this project, but building on top of those results is fine.\nPast projects have included comparing ML algorithms on remote sensing data, predicting urban growth, and mapping plankton blooms.\nThe course needs to have an advisor; students can find one on their own, or work with me on a topic. A good approach is to find a professor whose classes you have enjoyed and ask them directly. Most profs are more than happy to advise an independent research project that aligns with their ongoing research.\nThis is (supposed to be) a fun course! You get to work on ideas and problems that are interesting to you.\nFailing is possible, and usually happens when students do not keep up with the work."
  },
  {
    "objectID": "teaching.html#combined-gradsenior-undergrad-courses",
    "href": "teaching.html#combined-gradsenior-undergrad-courses",
    "title": "Teaching and Materials",
    "section": "",
    "text": "SENG 480X/CSC 586X, Data Science for SE. Fall 22\nSENG 480X/CSC 586X, Documenting and Understanding Software Systems."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research & Publications",
    "section": "",
    "text": "My research explains the how and why of software, based on user intentions. We want to know that our software is doing what we told it. We also want to know the reasons our software does something unexpected. Finally, we want to be able to design software to meet our intentions in the first place. Some recent and ongoing projects:\n\n All Publications\nFor a complete list, or mostly complete, best to look at one of the following sites.\n\n\n DBLP\n\n\n ORCiD\n\n\n Semantic Scholar\n\n\n Google Scholar\n\n\n ArXiv\n\n\n MS Academic Search\n\n\n Slideshare\n\n\n SEI Digital Library\n\n\n SpeakerDeck\n\n\nI encourage you to check out Impact Story’s “UnPaywall” extension.\n\n\n Technical Debt and Software Documentation\nTechnical debt is a short-term software design choice that incurs long-term costs if not dealt with. We look at technical debt in requirements, in architecture, and for emerging machine learning systems.\n\n\n\n Qualitative Research and Peer Review\nWe are conducting studies into how qualitative research is emerging as a key research strategy for software engineering, which is, after all, highly subjective and contextual. A similar project looks at how we know what we know in software engineering, specifically for reviewing papers.\n\n\n Bayesian Statistics\nWe are examining ways to improve the state of the art of software research statistical approaches, particularly by eliminating null hypothesis testing. Bayesian statistics works intuitively with the highly contextual nature of software projects, which tend to vary in size, domain, criticality, and numerous other places.\n\n\n\n Software Requirements and Analysis\nMy background is requirements analysis and modeling, and this continues to be a passion of mine. All the funky stuff we can do with programming languages, testing, design, etc. is irrelevant if we are building the wrong thing.\n\n\n\n\n\n\n\n Theses\n\nN. A. Ernst, “Software Evolution: A Requirements Engineering Approach”. Ph.D. dissertation, University of Toronto, 2011. pdf (224 pages)\nN. A. Ernst, “Towards Cognitive Support in Knowledge Engineering: An Adoption-Centred Customization Framework for Visual Interfaces”, unpublished M.Sc. thesis, University of Victoria, 2004. pdf (95 pages)\n\nIcons from NounProject"
  },
  {
    "objectID": "posts/2016-03-07-on-using-open-data-in-software-engineering.html",
    "href": "posts/2016-03-07-on-using-open-data-in-software-engineering.html",
    "title": "On Using Open Data in Software Engineering",
    "section": "",
    "text": "I recently reviewed data showcase papers for the Mining Software Repositories Conference, and I’m co-chair of the Engineering track (subsumes datasets, tools, approaches) for the SCAM conference1. I’ve worked with a number of different datasets (both openly available and closed) for my research efforts. This caused me to do some reflection on the nature of empirical data in SE.\nWe’ve had a nice increase in the amount of data available for researchers to explore, and most recently, the amount of well-constructed, easily understandable and accessible datasets – like the GHTorrent tool – is impressive (traditionally it has been difficult to get any credit for creating these resources). I think it is a hugely beneficial effort for our efforts to create a well-grounded, empirical basis for software engineering (as opposed to pie in the sky theorizing).\nI have two concerns that threaten this idyll."
  },
  {
    "objectID": "posts/2016-03-07-on-using-open-data-in-software-engineering.html#footnotes",
    "href": "posts/2016-03-07-on-using-open-data-in-software-engineering.html#footnotes",
    "title": "On Using Open Data in Software Engineering",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSubmit early, submit often!↩︎\nJorge Aranda’s ‘secret life of bugs’ paper sheds light on this.↩︎\nYou put your freaking email on Github! What did you expect!? (sigh)↩︎"
  },
  {
    "objectID": "posts/2015-08-25-running-a-critical-research-review-at-re15.html",
    "href": "posts/2015-08-25-running-a-critical-research-review-at-re15.html",
    "title": "Running a “Critical Research Review” at #RE15",
    "section": "",
    "text": "Today we conducted our first attempt at “Critical Research Reviews” (CRR) at our workshop on empirical requirements engineering (EmpiRE) at the 2015 Requirements Engineering Conference.\nCRR was introduced to me by Mark Guzdial’s post on the same exercise at ICER last year, which was run by Colleen Lewis. The idea (as I understand it) is to have researchers present work in progress, ideally at the research design stage. The purpose of the workshop is to “leverage smart people for an hour” in improving and stress-testing your research idea and methodology.\nThe cool part about doing this at EmpiRE is that our proposers got to leverage some of the leading empirical researchers in the RE community. These are the people likely reviewing your full paper, so it makes sense to get their critique up front.\nWe had three accepted “research proposal” papers as a special category for the workshop call. In the afternoon, (2pm-5.30pm) we had the three presenters do a 15 minute plenary presentation to get everyone in the workshop (25 or so) aware of the work. I restricted any questions so this was almost entirely over in 45 minutes. After a coffee break, I introduced the CRR concept and some ground rules, as well as a list of potential questions to consider. Then, for the next 45 minutes or so, the participants were invited to join the presenter that interested them and have a (polite) discussion about the proposed research.\nFinally, I had asked each group to bring some wide-ranging thoughts back for the entire group for the last 30 minutes. My intent here was not to go into specifics on the proposals; rather, to get some other lessons that might be useful for the people who were not part of that particular group. This worked pretty well; it did tend to go into more detail than perhaps warranted, but it did stimulate some interesting discussion.\nFrom what I heard, people quite enjoyed this approach to research evaluation. It’s much more fun trying to poke holes in research approaches when the author on the other end can rebut your arguments!  Look for another edition next year.\nYou can find my slides introducing the idea here, and our proceedings, with the presenters’ research proposals, will be posted whenever IEEE gets around to it.\nLessons learned\n\nThe room was terrible: large central conference table. One group retreated to the coffee room which had large circular tables.\nNo one used the flip charts: I think the presenters were writing their own notes down on their laptops anyway.\nWe mostly had established researchers presenting. In the future we are considering perhaps restricting this to early career or Phd students, who likely need the assistance more. But I think the more senior researchers still benefited. The primary difference, I think, will be that the senior researchers will have considered more of the potential threats.\nI was main facilitator: having one group a 2 minute walk away made this harder. No group really needed help, but I can certainly see possibilities where that would be an issue. For instance, if you get too many people going to one presenter, or one person dominating the discussion, or too much negativity (the usual group dynamics, in other words)."
  },
  {
    "objectID": "posts/2013-11-20-evidence-in-software-engineering.html",
    "href": "posts/2013-11-20-evidence-in-software-engineering.html",
    "title": "Evidence in Software Engineering",
    "section": "",
    "text": "This post is spurred by a line in a paper of Walker Royce, son of Winston Royce, he of the “waterfall model” (misunderstood model). He says\n\nwithout quantified backup data, our software estimates, proposals and plans look like long-shot propositions with no compelling evidence that we can deliver predictably or improve the status quo.\n\nBold text is mine, to emphasize this notion of evidence. The question then becomes what evidence is acceptable. And here I think we get into some hoary philosophical questions concerning truth in science (epistemology, really).\nI think one of the fundamental impedance mismatches in software engineering for large-scale systems, or software engineering in a systems engineering environment (e.g., airplanes, military software, ultra-large-scale software, safety-critical software) is that a number of people on those teams have a positivist view of evidence. They subscribe to the notion that sufficient “data” can show whether something will work or not. So if you design a missile system’s rocket engines, those engines either deliver the necessary thrust, navigability, etc. or they do not (actually, I think this is probably not the case in those so-called hard sciences either, but the point is that people from those domains think it is the case).\nAgile software delivery works much more from the falsificationist or even outright constructionist approach. I would estimate that the majority of agile practitioners believe in the test and refine approach, where you deliver an increment, test it to determine how well the ‘theory’ of that software matches reality, and then iterate. The key difference with the positivists being, of course, that there is no a priori evidence you can use to show things will work. It is hard to do simulations in Simulink or Matlab as to how well software will perform. This is why Alistair Cockburn calls software development a cooperative game. And some people, I would say, would go even further and treat software development as a post-modernist exercise in building the reality you want to see and dispensing with evidence altogether (“if it works, it is right”). Those people probably don’t get a lot of government contracts, however.\nBack to the quote: the issue remains, how easy is it to produce “compelling evidence” and what does it consist of? In Royce’s view, evidence takes the form of historical context for productivity, function points, etc. In that case we are almost measuring the team’s capability to deliver more than any particular artefact.\nAt some level, cynically one might say, there is a need to show the ‘evidence’ that will get the job or contract. People hire companies like Thoughtworks because they have a track record of getting the job done to people’s satisfaction. We don’t much care how long it took, or how many lines of code were written, if the software was valuable.\nWhich is fine, but as an engineering discipline one would like a bit more to chew on."
  },
  {
    "objectID": "posts/2013-03-12-the-fuzzy-notion-of-business-value.html",
    "href": "posts/2013-03-12-the-fuzzy-notion-of-business-value.html",
    "title": "The fuzzy notion of “business value”",
    "section": "",
    "text": "Software development is rife with references to business value, particularly in agile approaches: the Agile Manifesto declares that “Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.”\nThe trouble is that it isn’t clear what ‘valuable’ means. I’m sure that the point of this phrase, as with most of the Manifesto, is to start a discussion rather than to behave as a prescriptive methodology. I believe “value” is inherently context-dependent, so in that sense it is reasonable to leave it vague.\nOn the other hand, many people refer to business value as the Holy Grail of software development: this is what you are supposedly optimizing in Scrum. Other methodologies help focus on “impact”. Lean approaches have one remove ‘waste’ from the value stream. And yet no one has ever pinned value down, as Racheva et al. have shown [1] (in the software domain, anyway - many attempts have been made in economics).\nBusiness value does have the nice property of communicability, though. It gives developers that one number to sell the project to the business, and allows for a conversation about scope, cost of delay, and prioritization that is difficult to do with purely qualitative methods. And for the mathematically inclined, it lends itself to algorithms like linear programming for optimization.\nOne paper does try to break business value into more reasonable components, which I quite liked. It is by Heidenberg et al. [2]. They break business value into five dimensions, each of which is ranked on an ordinal scale with four possible categories:\n\nMonetary Value - this is the number calculated by, say, a business analyst.\nMarket Enabler - does delivering this feature create new market opportunity?\nTechnical Enabler - does this feature help prepare the company for other features?\nCompetence Growth - measures how much the work will improve the team’s skill.\nEmployee Satisfaction - do the developers like working on this feature?\nCustomer Satisfaction - how much will customers appreciate this work?\n\nOne of the big problems with agile planning is that making categories 2, 3, 4, 5 visible is often hard. It is comparatively easy to sell a customer a feature that ranks highly in monetary value or customer satisfaction - these are the slick and cool UI widgets, the mission-critical Word reporting function, and so on. But making architectural work (category 3) visible is very challenging. If we had this six-factor model, prioritizing important architectural work would be easier.\n[1] Z. Racheva, M. Daneva, and K. Sikkel, “Value Creation by Agile Projects: Methodology or Mystery?,” presented at Product-Focused Software Process Improvement, 2009, vol. 32, no. 12, pp. 141–155.\n[2] J. Heidenberg, M. Weijola, K. Mikkonen, and I. Porres, “A Model for Business Value in Large-Scale Agile and Lean Software Development,” presented at EUROSpi: Systems, Software and Services Process Improvement, 2012, pp. 49–60."
  },
  {
    "objectID": "posts/2014-06-13-software-research-shouldnt-be-about-the-tools.html",
    "href": "posts/2014-06-13-software-research-shouldnt-be-about-the-tools.html",
    "title": "Software research shouldn’t be about the tools",
    "section": "",
    "text": "It comes down to essential vs. accidental complexity, as outlined by Fred Brooks. What we research is new ways to ‘nibble’ at the accidental complexity: new languages (GO, Swift), new abstractions (Actors vs. functional programming in distributed systems), new methodologies (random test case generation). It’s what nearly every story on Hacker News is about.\nBut ultimately, I think most problems come down to two factors: the problem complexity itself, and the team tackling it. To me, many of the problems highlighted as software/IT failures, like the FBI registry, have nothing to do with a lack of good tools or techniques. These are ultimately management failures: scope creep, poor leadership, insufficient budget, too much budget, negative work environments, etc. It is ‘executing’ that is the problem, not the technology. How many errors have been caused by the US reliance on imperial units?\nLook at this quote by a senior VP at Oracle on failures in implementing CRM projects:\n\n[M]y comments apply to ALL CRM vendors, not just Oracle. As I perused the list, I couldn’t find any failures related to technology. They all seemed related to people or process. Now, this isn’t about finger pointing, or impugning customers. I love customers! And when they fail, WE fail.\n\nI’d be willing to say that software engineers have all the tools they need. We need some form of continuous integration and deployment, abstraction mechanisms to simplify the problem, tests to verify our solution, version control to maintain a history of changes, and some form of requirements (whiteboard, paper, spreadsheet, what have you) to keep track of what needs to be built. I don’t even think it particularly matters how you use those tools. If you have a mature organization and process then you can all into the following matrix (James Montier via Jonathan Chevreau):\n\n\n\n\n\n\n\nGood Outcome\n\n\nBad Outcome\n\n\n\n\nGood Process\n\n\nDeserved Success\n\n\nBad Break\n\n\n\n\nBad Process\n\n\nDumb Luck\n\n\nPoetic Justice\n\n\n\n\n\nBut just having the right tools, the good people, and a mature process is not enough to guarantee success, of course. You could be tackling a ‘wicked problem’. You could have a team of misfits and losers. You could have a manager who refuses to accept responsibility or make decisions. Most software research does not address those issues. I’m not convinced there is any research that addresses those issues: leadership, management, sociology… nothing can help when your team lead is having a marital crisis and can’t devote any time to product development."
  },
  {
    "objectID": "posts/2015-10-27-how-writing-code-is-like-making-steel.html",
    "href": "posts/2015-10-27-how-writing-code-is-like-making-steel.html",
    "title": "How Writing Code is Like Making Steel",
    "section": "",
    "text": "I saw an interesting keynote from Mark Harman recently, on search-based software improvement. Mark’s lab at UCL also pioneered this idea of automatic code transplants using optimization techniques.\nI think if you are an engineer who does fairly standard software development you should be concerned. The ultimate vision is to be able to take some specification with thorough tests, written in a language at a high-level of abstraction (e.g., here is my corporate color palette, here are my security requirements) and automatically generate the application.\nThere are several forces at play here. One is the increasing componentization of large and complex pieces of software. We’ve always had software reuse, but it tended to be at a much smaller level - the ODBC api, or the OAuth framework. Now our frameworks reach much larger areas of concern, particularly when we look at container technology running on commodity hardware. Someone else is maintaining huge chunks of your software base, in those cases: the OS, the backend, the messaging system, etc. If you then take your Rails app and add it to that stack, how much, as a %, have you created? A decreasing amount, in any case.\nThe other force is the improvements in genetic and other optimization algorithms, combined with the inevitable scaling of computing power. That means that even though you may be really good at crafting code, and the machine generates garbage, it can improve that garbage very very quickly.\nHow different is it for me to copy and paste the sample code on the Ruby on Rails site to create a new application, than for a computer algorithm to follow those same steps? To be clear, there remain a lot of complex decisions to make, and I’m not suggesting algorithms can do so: things like distributed systems engineering, cache design, and really just the act of taking a user requirement and turning it into a test.\nSo how is this like the steel industry? I think it reflects commodification and then automation. Steel was largely hand-made for years, but the pressure of capitalism generated rapid improvements in reducing costs - largely labor costs. Process and parts became standardized, so it was possible to set up mills at much lower cost. The difference in quality between US and (say) Indian steel became small enough to not matter. But even in India, the pressures continue downward, so India’s dramatically lower labor costs still cannot compete with automation.\nSome of these pressures don’t exist in software, of course: there is still a large knowledge component to it, and there are no health and safety costs in software labor (the hazards of RSI and sitting notwithstanding). So I don’t see any big changes immediately, but the software industry is probably where the steel industry was in the 20s. In 50 years I cannot see software being written by hand at the level it is now, with the exception (like in steel) of low-quantity, high-tolerance products like embedded development. The rest will be generated automatically by algorithms based on well specified requirements and test cases. Silicon Valley will become the rust belt of technology. You realize that Pittsburgh, birthplace of the steel industry, was once the most expensive city in the US, right?\nIf you doubt this, I think we are really arguing over when, and not what. My simplest example is coding interviews. Why test people on knowledge of algorithms that are well understood, to the point where they are in textbooks and well-used library code? The computer can write the FizzBuzz program faster and more efficiently than a human can. Over the next few decades, I believe Mark Harman’s optimization approach will encompass more and more of what we now do by hand."
  },
  {
    "objectID": "posts/2013-09-24-13-great-software-architecture-papers.html",
    "href": "posts/2013-09-24-13-great-software-architecture-papers.html",
    "title": "13 Great Software Architecture Papers",
    "section": "",
    "text": "In the paper “The Past, Present and Future of Software Architecture”, the authors (Philippe Kruchten, Henk Obbink, and Judith Stafford) have a sidebar in which they list their selection of “Great Papers of Software Architecture”. I’ve tried to collect these papers and links thereto for future reading. Here is a bibtex file for full citations. I’ve also included the parenthetical comments of Kruchten et al. in italics, and my comments in bold. Unless otherwise noted I’ve linked directly to the PDFs (please let me know if a link breaks)."
  },
  {
    "objectID": "posts/2013-09-24-13-great-software-architecture-papers.html#foundations",
    "href": "posts/2013-09-24-13-great-software-architecture-papers.html#foundations",
    "title": "13 Great Software Architecture Papers",
    "section": "Foundations",
    "text": "Foundations\n\nGarlan and Shaw, “An Introduction to Software Architecture”—Shortly preceding their book, this paper brought together what we knew about software architecture in the beginning of the 1990s.\nD.E. Perry and A.L. Wolf, “Foundations for the Study of Software Architecture,”—This seminal paper will be always remembered for giving us this simple but insightful formula: {elements, form, rationale} = software architecture."
  },
  {
    "objectID": "posts/2013-09-24-13-great-software-architecture-papers.html#precursors",
    "href": "posts/2013-09-24-13-great-software-architecture-papers.html#precursors",
    "title": "13 Great Software Architecture Papers",
    "section": "Precursors",
    "text": "Precursors\n\nD.L. Parnas, “On the Criteria to Be Used in Decomposing Systems into Modules,”—Software architecture didn’t pop up out of the blue in the early 1990s. Although David Parnas didn’t use the term “architecture,” many of the underlying concepts and ideas owe much to his work. This article and the next two are the most relevant in this regard._\nD.L. Parnas, “On the Design and Development of Program Families”\nD.L. Parnas, P. Clements, and D.M. Weiss, “The Modular Structure of Complex Systems”\nF. DeRemer and H. Kron, “Programming-in-the-Large versus Programming-in-the-Small,” —Their Module Interconnection Language (MIL 75) is in effect the ancestor of all ADLs, and its design objectives are still valid today. The authors had a clear view of architecture as distinct from design and programming at the module level but also at the fuzzy, abstract, “high-level design” level."
  },
  {
    "objectID": "posts/2013-09-24-13-great-software-architecture-papers.html#architectural-views",
    "href": "posts/2013-09-24-13-great-software-architecture-papers.html#architectural-views",
    "title": "13 Great Software Architecture Papers",
    "section": "Architectural views",
    "text": "Architectural views\n\nD. Soni, R. Nord, and C. Hofmeister, “Software Architecture in Industrial Applications,” —This article introduced Siemens’ five-view model, which the authors detailed in their 1999 book Applied Software Architecture\n__P. Kruchten, “The 4+1 View Model of Architecture,” —Part of the Rational Approach—now known as the Rational Unified Process—this set of views was used by many Rational consultants on large industrial projects. Its roots are in the work done at Alcatel and Philips in the late 1980s."
  },
  {
    "objectID": "posts/2013-09-24-13-great-software-architecture-papers.html#process-and-pragmatics",
    "href": "posts/2013-09-24-13-great-software-architecture-papers.html#process-and-pragmatics",
    "title": "13 Great Software Architecture Papers",
    "section": "Process and pragmatics",
    "text": "Process and pragmatics\n\nB.W. Lampson, “Hints for Computer System Design,”—This article and the next gave one of us (Kruchten), a budding software architect in the 1980s, great inspiration. They haven’t aged and are still relevant.\nJ.A. Mills, “A Pragmatic View of the System Architect,” paywall\n****W.E. Royce and W. Royce, “Software Architecture: Integrating Process and Technology,” —This article articulates the connection between architecture and process very well—in particular, the need for an iterative process in which early iterations build and validate an architecture. Not online, sadly."
  },
  {
    "objectID": "posts/2013-09-24-13-great-software-architecture-papers.html#two-more-for-the-road",
    "href": "posts/2013-09-24-13-great-software-architecture-papers.html#two-more-for-the-road",
    "title": "13 Great Software Architecture Papers",
    "section": "Two more for the road",
    "text": "Two more for the road\n\nM. Shaw and P. Clements, “A Field Guide to Boxology: Preliminary Classification of Architectural Styles for Software Systems,”\nM. Shaw, “The Coming-of-Age of Software Architecture Research,”."
  },
  {
    "objectID": "posts/2015-01-20-frameworks-libraries-and-dependencies.html",
    "href": "posts/2015-01-20-frameworks-libraries-and-dependencies.html",
    "title": "Frameworks, libraries, and dependencies",
    "section": "",
    "text": "I’ve been doing a little thinking about frameworks lately. They fascinate me as 1) a realization of the vision of ‘pluggable software’ and reusable components desired since probably 1968; 2) what you are getting into when you rely on one. This is prompted by this great post on libraries vs frameworks.\nNow, we’ve used libraries for ages, viz. glibc etc. And the notion of ‘code that someone else wrote and maintains that I need’ was likely established in the design of Unix and pipe and filter architectures. But it really seems like the past 10 years have seen this wonderful explosion of creativity in writing ‘little libraries’ for various different systems.\nI’ll take a common example. I’ve previously used Node.js for a small visualization I did for my brother’s work on genetics (in progress!). Although an academic, I like to try to stay on top of things, so I tried out Node, the Javascript web server. Now JS itself has at least60+ frameworks and libraries, and that list doesn’t even include Node or some of the ones I’ll describe below. This is amazing considering although JS has been around a long time, only recently (would we say JQuery is the prototypical case?) has this explosion happened.\nThe trouble is that like the Cambrian explosion, some of these libraries and frameworks are doomed to extinction. If you are BigCo, that makes choosing one very tricky, in addition to the licensing and security questions you will need to ask.\nConsider. I wrote the application for the Node server, using Express as a web framework (that means it automates some of the routing and layout of files and directories for you). To get to the database I used the Node PostGreslibrary. To do UI I relied on JqueryUI and Stylus for CSS, with Jade for templating. Then I used Morgan for logging, Gulp to automate the style generation from the Stylus files, and was toying with D3 to do the display. Not to mention I need a Platform as Service from Heroku, so I have their command line tools installed as well.\nSo that gives about 10 different libraries to run this app. On the plus side, they automate a ton of code I no longer have to worry about, letting me focus on the key value-add of the app (realized in the SQL code I write and custom request handling code).\nBut I just upgraded to Express 4, and they’ve broken the back-compatibility, so I must now understand what the changes mean and how to retrofit them. Who maintains these libraries? Will he or she keep updating it? These are by no means new questions, but I think what has changed is that now it is very hard to avoid using them. And once you commit to it, re-architecting for the problems you will inevitably face with leaky abstractions seems challenging, because everything is deeply connected. You cannot just drop in a new back end server with the same libraries.\nNow imagine that multiplied times 10 years and instead of my simple app, a mission critical information system, and you start to get a sense of the problem that legacy applications can pose. Fortunately, I work at a place with lots of experience solving those problems, so give us a call if you need help!"
  },
  {
    "objectID": "posts/2020-09-30-kaggle-mining.html",
    "href": "posts/2020-09-30-kaggle-mining.html",
    "title": "Running a Mining Challenge Using Kaggle",
    "section": "",
    "text": "For the 2nd edition of the Dynamic Software Documentation (DysDoc) workshop, the organizing team wanted to push the boundary on how to engage the community in tool supported demos. Previously, we had asked participants to come to the workshop (co-located with ICSME) with a tool to demo, live, to the other attendees. One of the goals was a tool that worked on unseen data.\nThis year, at our organizing meeting, we wanted to try something that went beyond documentation generation, and looked at other issues with dynamic documentation fixes. A study by Walid Maalej and Martin Robillard, which looked at types of API documentation, included an interesting issue with documentation - code comments - that were uninformative.\n/** \n *  Clears the log\n */\npublic void clearLog() {\n  LogMessages.getInstance().clear();\n}\nThis comment is clearly not adding information to the code, and in fact, might even be harmful, if it were to be outdated. Thus our “Declutter” Challenge: figure out a way to identify these type of comments and (eventually) target them for removal. I was co-organizer alongside Nicole Novielli.\nWe were inspired by the success of datasets and benchmarks such as Fei Fei Li’s ImageNet contests, or the SAT competition. Both of these have been influential in driving innovation in graphics and satisfiability solving. As it turned out, these distributed competitions were also ideally suited to the new remote work paradigm that was required during the COVID pandemic.\nTo set up this competition, there was the option to have the competitors take the dataset, work on a solution, then submit their solution to the organizers for evaluation. Of course, this involved a lot of work on the part of the organizers, and being fairly lazy, I looked for an alternative approach. Immediately the Kaggle competition platform seemed the way to go: it has been hosting large-scale data science competitions since before there was data science.\nI therefore investigated how this could work. Normally, hosting Kaggle competitions require payment (commercial) or prizes (academic). Academic contests are also selected by Kaggle. Fortunately, Kaggle makes the platform available for classroom use, on Kaggle InClass. The difference, other than no support, is that competitors do not get Kaggle points for entering. Nicole and I thus decided to use Kaggle to host the Declutter challenge, which you can find here.\n\nWhat Worked\nDespite lacking support, getting the contest going on Kaggle was fairly simple. Nicole organized labeling with the rest of DysDoc’s organizers, and hosted a gold set on Github. I then used the gold set to generate the inputs Kaggle wanted. This includes the gold set, split into training and test. Test data is further split into “public leaderboard” and “private leaderboard”, since competitors can submit multiple entries, and see where they stand on the leaderboard. Only the organizers get to see the private leaderboard, which is what ultimately ranks the competitors. You can see that in practice here.\nI also had to choose between Kaggle’s available validation metrics, in this case choosing F1, and this can be a bit finicky, as you have to map between the columns in the solution CSV file and whatever Kaggle’s automation expects. Clearly at paid support levels they would make this simpler, or just do it for you.\nDespite not having a lot of labeled data, we managed to get a good set of data, and Kaggle’s infrastructure worked - as far as I know, anyway! - with no problems. Competitors download the data, run their model, and then upload a solution file with their predicted labels.\nWe managed to get 2 principal competitors, one of whom submitted several distinct entries. Both entrants published their submissions at our workshop, which can be found at the ICSME proceedings site.\n\n\nImprovements and Questions\nI was quite happy with how simple Kaggle made the process of evaluating entries. It also scales flawlessly (unlike me), and in theory, could help us dramatically expand our contest. In the COVID era, of course, it also made it pretty easy to host a remote contest, unlike our previous approach, which used in-person demos.\nIt would be nice to have more support for notebooks, or perhaps a mandatory notebook submission, so that we can see how each group approaches the problem (after it finishes of course).\nAs far as I am aware, this is one of the first challenges to be hosted on Kaggle. To me it seems like an obvious choice for running and hosting automated benchmarks, such as the various effort estimation and defect prediction datasets out there. If we could disambiguate entries, that would help with understanding who is entering.\nKaggle makes it possible to host an ongoing, never-ending contest, which is also appealing. The obvious bottleneck, unsurprisingly, is data annotation, and at this point I would say that is the main obstacle to running more such contests. However, we have tentative plans to continue the approach in future workshops."
  },
  {
    "objectID": "posts/2016-11-04-ko-splash.html",
    "href": "posts/2016-11-04-ko-splash.html",
    "title": "Thoughts on Amy Ko’s “PL as …” keynote",
    "section": "",
    "text": "Amy Ko had a great presentation at a conference on programming languages (PL), that he also video taped for a wider audience.\nI’d always thought of PL as “things”, or material. The program was the interesting bit; the PL was the material that constructed it. But I guess as I extend that metaphor, it seems clear that it falls short. Cedar, for instance, is a material, and the building is the interesting thing. But cedar has intrinsic properties as well. You can bend it without cutting it to make a box.\n\n\n\nbentwood box\n\n\nIt weathers beautifully due to the oils it contains, so you can make shingles and siding out of it. It burns very easily. If we extend the definition of cedar to include the tree itself, we can make canoes, rope, hats, spears, and so on. Cedar was a crucial part of Northwest aboriginal culture.\nAnd so in translating that thought back to the PL world, it seems clear that PL also has this. The syntax of Java vs C in ease of learning the language. The ecosystem of Javascript vs Clojure in building apps. The culture of web programming languages vs scientific programming languages. And so on.\nThe one quibble I have—clarification, to be more accurate—is the slide on definitions, values and community weighting toward the end. The \u0003implication → goes one way for a reason. That is, because we chose to focus on PL as math, we have, as a result, a lot of focus on the value of certainty. But that isn’t to say because we value certainty, we focus on PL as math. In fact the reason for ‘valuing’ this value are complex and systemic: most CS departments started with math graduates, most CS departments still contain math-heavy disciplines like theory and machine learning, we want to show correctness and soundness, and math is the way to do it. So it isn’t to say that PL community does not value equity, or the others, but rather that equity is hard to prove, and PL academics function in a math world.\nFinally, Amy had this great list of what form PL takes, and associated research questions, which I’ve shamelessly duplicated here so people can more easily copy it.\nProgramming languages as ….\n\npower\n\nwhat responsibilities does knowing PL come with?\nhow does PL corrupt?\nshould democracies distribute it?\n\ndesign\n\nwhat tradeoffs are made?\nwhat is a “good” PL design process?\nhow can we rapidly prototype PL?\nwhat are PL aesthetics?\n\nmedia\n\nwhat message is enabled by PL?\nhow does PL facilitate expression?\n\nnotation\n\nwhat can PL not model?\nwhat info can PL not share?\nwhat makes a PL learnable?\n\ninterfaces\n\nhow can PL convey what is possible?\nhow do we make PL usable?\nwhat feedback must a PL provide?\n\nmath\n\nwhat does PL correctness mean\nhow to prove PL correct?\nwhat in PL is equivalent?\n\nlanguage\n\ndo PL have ambiguities?\ndo PL shape how we computationally think?\n\ncommunication\n\nShould PL model developer intent?\nshould PL express intent to developers?\n\nglue\n\nwhat makes a PL a good adhesive?\nwhat materials do PL adhere to?\n\nlegalese\n\nwho should interpret code legally?\n\nare programmers lawyers?\n\n\ninfrastructure\n\nhow do PL decay?\nhow should we maintain PL?\nis PL a public good?\n\npath\n\nshould gov’t create the path?\nhow do we make PL equitable?\nwho should go down this path?"
  },
  {
    "objectID": "posts/2021-03-03-teaching-factors.html",
    "href": "posts/2021-03-03-teaching-factors.html",
    "title": "The Triumvirate of Teaching and Work Life Balance",
    "section": "",
    "text": "Most courses have a series of learning outcomes for students. Once you have done the course (and, I assume, gotten a B or some reasonably high mark), then you know how to accomplish the learning outcomes.\nSome may break those learning outcomes down to smaller units per module.\nFor instructors, it occurs to me there are three objectives to balance (at least):\n\nHow much effort it takes to teach the topic\nHow much students appreciate the topic and teaching choices\nHow much students learn after being taught\n\nNumber 2 is not ever considered in pedagogy, but is the ONLY thing that matters from a management point of view. It maps directly to the things RateMyProf and course evaluations measure. Therefore from a pragmatic point of view, a prof should only care about 1 and 2.\nNumber 3 is what pedagogy is all about: how much are students learning? This is what is referred to when we look at things governments fund us to do. They want more “skilled workers”. Students in the short-term don’t really care much about this stuff. And course evaluations don’t really test for this. Teachers who are really good at 3 often end up getting punished for 2 (learning things is hard and not fun!)\nNumber 1 is often ignored, too, but can be the difference between having a good term and a shitty term. For any given topic, there are many ways to think of teaching that topic. Take data flow diagrams:\n- we could lecture off a set of slides showing DFDs\n- We could use a textbook reference and just skim the topic\n- We could create a detailed case study and show DFDs by construction\n- And for each of these, we could come up with different teaching strategies: whiteboard, live coding/drawing, interviewing experts etc.\nAs someone with limited time, one goal has to be minimize #1. My contention is that it is easy to go for perfection in 3 and absolutely devastate yourself in #1.\nWhat I try to do is:\n\nDestroy with fire any plan that maximizes 1, but minimizes 2 and 3. If students aren’t learning, aren’t enjoying it, and it is a lot of work, you should NEVER do it. And I bet you would be surprised how often this case happens. For example, in my third year software design course I spent a ton of time (increasing 1) ingesting the Play framework, learning how it worked, so that students could use it in the project. But it was a huge pain for the students to work with (hurting 2), they wanted to use React instead (hurting 2), and most of the learning was about the Play framework itself, rather than software design concepts (hurting 3). I won’t be doing that again.\nRuthlessly assess how important #3 is for your career. I haven’t seen anyone whose teaching packet evaluates 3. And yet it seems like we all talk about how it is the only goal. I really hope researchers improve on this. For tenure, for example, I seriously doubt anyone is looking at this. The closest we come is peer evaluation, but as Mark Guzdial wrote, this is often the blind leading the blind.\nTeaching awards seem to be about 2: winners tell jokes, they dress nice, they are male, they seem knowledgeable.\nGiven what we think we know about how software is built, I am going to guess that some teachers are really effective (either for 2 or 3) for minimal effort, and others put in orders of magnitude more time on 1, but have little extra to show for 2 or 3. I believe there is a non-linear, diminishing returns model for teaching effort; you might do 10 hours of prep for a lecture and not have much more to show for (3) then if you had done 1-2 hours.\nThere is a sunk cost/amortization problem here, too. If you teach a course the first time, you may have a lot of 1 to pay off. Subsequent offerings might greatly reduce 1 and allow you to focus on 3 (or 2) to a greater extent. But I’m not sure how much this is true. Things move fast in software courses, especially in 2nd year and above, some costs simply don’t amortize (marking), and we often try to improve the course year to year. Plus, we might not get to teach that course more than a few times.\n\nI want to be clear that I am not endorsing a focus on teaching for “show” instead of long-term learning. 3 is clearly the goal. But the reward structure does not reflect this. We should figure out how to ensure that teaching is measured against outcomes on 3, and not on 2 (2 is also horribly biased!).\nMore importantly, there seems to be embarrassingly little data on how to minimize 1 and maximize 3. I think this is a problem. We have a lot of info on (for CS1 at least) how to best teach linked lists, such as using Parsons problems. But frankly, my job involves teaching 40% of my time. I may not be able to dedicate the time required to prepare Parsons problems for the course. So a “cost/benefit” (1 vs 3) analysis would be very useful to help me maximize the teaching effectiveness for unit of teaching effort."
  },
  {
    "objectID": "posts/2023-05-14-bots-in-SE.html#tasks",
    "href": "posts/2023-05-14-bots-in-SE.html#tasks",
    "title": "On Bots in Software Engineering",
    "section": "Tasks",
    "text": "Tasks\n\nDetailed tasks: Mylyn style tasks that have to do with a specific problem like finding a bug, refactoring a method\nHigh level tasks: get an overview of the system in order to see how it is progressing. This bot might send a weekly update on lines of code added. Sort of exists as Github’s various visualizations.\nDesign tasks: help me understand how the software will respond to quality attribute requirements."
  },
  {
    "objectID": "posts/2023-05-14-bots-in-SE.html#tasks-bots-can-help-with",
    "href": "posts/2023-05-14-bots-in-SE.html#tasks-bots-can-help-with",
    "title": "On Bots in Software Engineering",
    "section": "Tasks bots can help with",
    "text": "Tasks bots can help with\nAre bots just “API endpoints”?\nBots are api calls plus “vocal tics” like the fridge in Silicon Valley\n\n“It’s bad enough it has to talk. Does it need fake vocal tics like ‘ah’?\n“The tics make it seem more human,” Dinesh tells Gilfoyle.\n“Humans are shit,” Gilfoyle replies. “This is addressing problems that don’t exist. It’s solutionism at its worst. We are dumbing down machines that are inherently superior.”\n\nThe challenge in these systems has always been that entry level knowledge is extremely easy to retrieve, but going deeper is way harder (kind of like self-driving). For perhaps 80% of the interactions online, the bot can manage. But it is in the details that bots get stuck and need to call for the operator to step in. We saw something like this with expert systems. Coding something that can advise people to call their doctor when they report a fever of 102 or higher is pretty simple. But the complex explanations as to what is causing the fever are fairly intractable (explanation is usually thought of as NP hard, after all). Getting the knowledge in to solve the problem (basically, all the heuristics and learning that an experienced GP would have) is very expensive - the KA bottleneck. This is probably less costly now with deep learning. But the other bottleneck is the reasoning. Even if we have that knowledge, inference to multiple competing explanations is very expensive. Recommending the most common explanation—such as viral ear infection in a toddler—is what bots basically do now, but in many cases there isn’t a clear common explanation, or there is no clear set of symptoms to diagnose."
  },
  {
    "objectID": "posts/2023-05-14-bots-in-SE.html#bots-for-td-reduction",
    "href": "posts/2023-05-14-bots-in-SE.html#bots-for-td-reduction",
    "title": "On Bots in Software Engineering",
    "section": "Bots for TD reduction",
    "text": "Bots for TD reduction\nOne area we see a lot of activity is in static code analysis to find rule violations. There are more rules than programmers could reasonably want to use; code quality checks, syntax warnings, code smells, etc. The problem in fact is these warnings annoy developers. At Google they had a scheme where the code checks would be rejected if they had more than 10% false positives which developers could vote on. These tools generate multiples more warnings than developers actually take action on.\nHow could bots help? Well, the main issue I notice is the need for interactivity. Bots could easily process the boring problems in one shot (fix all trailing commas), but more importantly the bot could be an interface to the tool, instead of the common approach which is either a dashboard with TMI, or some simple weekly report. The bot instead could be a text interface to the tool itself, and run predefined queries or make new queries, adapting on the fly as the situation demands it. So bots are good for rapid re-contextualization which you do not see with dashboards, which require sophisticated analysis to configure.\nA bot is also automatable so it could delivery weekly updates to the developer without him or her having to do anything with that info. Again though it seems like we are pushing the complexity - what reports do I really need - into another interface. The tough problem in TD presentation is to figure out exactly what context underlies the data and only show that.\nWe need to find problems and generate data\nWe need to filter and store the data\nWe need to query the data\nWe need to visualize the data.\nBots don’t make any of these easier per se…."
  },
  {
    "objectID": "posts/2022-06-03-Roles-of-PI.html",
    "href": "posts/2022-06-03-Roles-of-PI.html",
    "title": "The PI as COO",
    "section": "",
    "text": "Faculty at a research university wear many different hats. One analogy might be to the executive roles in a company. Now a company tries to make profit, which is usually not the goal in academia (quite the contrary). But still, one can think of the mapping like\n\n\n\n\n\n\n\nTitle\nTasks for Faculty Member\n\n\n\n\nCEO\nStrategy, overall planning, team management\n\n\nCFO\nBudgeting, managing funds, making “payroll”\n\n\nCIO\nFiguring out IT equipment, choosing between cloud, govt infrastructure, managing equipment\n\n\nCTO\nLooking at trends and new tools (e.g., Google Colab, VS Code, Qualtrics)\n\n\nCMO\nMarketing the team and PI to the world, creating a need for the lab’s products (papers)\n\n\n\nThe one role not listed here is the one that I think in many ways is the most important: COO. Now, I don’t know much about business roles, but to my mind the Chief Operating Officer is sort of similar to the executive officer of a submarine. They are the person who makes the business work: ensuring inventory is at the right level, planning for new space as the company grows, managing supply chains, etc. Tim Cook, now CEO at Apple, made his name growing Apple’s manufacturing to the vast network it is now. That meant ensuring secrecy, getting supplies to factories, scaling to manage millions of devices being released at the same time, etc. Apple isn’t profitable and gigantic if the day-to-day operations aren’t running efficiently.\nBut the same is true in academic life!\nI think of the analogy as requiring thought and attention to the day to day management of productive work in the university. You need to make sure the ‘operations’ are smooth. One small component of this is the paper funnel: we need to ensure we have a lot of ideas in our funnel, that they get turned into data collection and analysis, and that the analysis gets written up and submitted, and eventually published. This is Arvind’s statement below about “getting sh*t done”, because it can be frustrating to think of oneself as moving papers from idea to publication. We want to pretend we are supposed to be thinking about ideas, noodling on the whiteboard, and being inspired by genius. And we are! But that’s not the COO part of the job.\n\n\nAcademics would double our productivity if we learnt some basic project management skills that are bog standard in the industry. We have this myth that scholarly success is all about brilliance and creativity, but in fact 90% of it is getting sh*t done, same as any other job.\n\n— Arvind Narayanan (@random_walker) June 2, 2022\n\n\n\nMetrics\nWe could look, like I’m sure Apple does, at operational metrics and efficiencies. For example:\n\nNumber of papers in draft/being reviewed/published (WIP)\nTime between idea and paper publication (lead time)\nStudents graduated in expected time\nNumber of important unanswered emails in Inbox\nTo the nearest thousand, how much money is in various accounts, and what the projected “burn rate” is for those accounts.\nHow long has each student been in the program, what milestones have they finished, and when they should graduate\nGrant money received\nGrants used efficiently\nReviews conducted within deadline\nTalks invited/given/follow up\nSize of industry collaboration address book\nTravel reimbursements received within 30 days of trip\nTime between equipment being needed and equipment being purchased and equipment delivered\n\nNow for some of these you might say “but someone else is blocking that!” Which is of course true of EVERYTHING and also not an excuse Steve Jobs was likely to accept. That’s all part of being efficient and operating smoothly. If you know the university takes forever to process room bookings, you need to factor that in to the operational goals.\n\n\nWhy Care About Operations\nI think operational efficiency is what separates average researchers from those seen as impactful. Sure, in some cases it might be a brilliant one-off paper, but often we reward output volume: “quantity has its own quality”. Did the project lead to a single paper, or did you harvest 3-4 papers from it? That’s an operational detail that has to do with a PI’s ability to direct students, target appropriate venues, manage meetings to keep the papers on schedule, and so on.\nI think the importance of the COO view of one’s career is that for better or worse these outputs are the easiest to turn into data, and subsequently evaluate you, and your institution. So ignoring number of students graduated, or number of publications, or grant values, will result in poor scores on these data metrics. It doesn’t matter how many brilliant ideas you have if no one gets to read them.\nThe question for this COO view of a research career is to figure out which metrics one truly cares about, and when to stop focusing on operations and think more about strategy and trajectory. Metrics, because the metrics you choose reflect your priorities (e.g., papers published vs industry collaborations nurtured), and strategy, because (hopefully) the research you pursue should reflect some higher level of understanding about what problems are important to be spending time on.\n\n\nMy approach\nFor me personally, it can be hard to remember to manage the operational details. The easiest way for me to see this concretely is when papers fail to meet a venue deadline. That’s an operational failure: we didn’t move fast enough on data analysis, the meetings were not productive and the project spun its wheels, I didn’t kill the project or value the cost of delay, I answered emails about committee work rather than spending 2 hrs editing.\nMy current management approach is to check in on each project (I have about 9-10 in various stages) weekly, using a dedicated card (using a note in Apple’s Notes tool). A Kanban board with stickies can be really helpful here too, but the important thing is not the particular system but that you use it and check it regularly.\nAnother idea I have just started to implement is reflecting on lessons learned from a project (e.g., after a paper is published). Not just the research problems, but the operational challenges. What would I do differently for project management? What worked well in moving the project along? Was this a productive collaboration? Why did it get delayed (it’s always delayed)?"
  },
  {
    "objectID": "posts/2018-06-16-satt.html",
    "href": "posts/2018-06-16-satt.html",
    "title": "Bayesian Hierarchical Modeling in Software Engineering",
    "section": "",
    "text": "At MSR18 in Gothenburg, I presented my work on using Bayesian inference to set software metrics thresholds. We want to set thresholds because for many software metrics, like coupling between objects (CBO), a single, global metric value (“all software objects with this value or below are maintainable”) is nonsensical, if only because programming language choice is important. So we want to tailor threshold values to some contextually relevant value (e.g., perhaps all Java code should be X or less). The question I answered is how we do the tailoring, given some contextual features.\nIn this case, the contextual features I was looking at were Java files categorized by architectural role in the Spring framework, derived from a paper by Mauricio Aniche and others.\nThe bottom line of this new approach is that we can use Bayesian inference and hierarchical models to perform a simple regression and get a 50% drop in root mean squared error (RMSE).\nThe more interesting conclusion from a methodology point of view is that hierarchical modeling with Bayesian inference fit software engineering data very well, and is straightforward to model given modern probabilistic programming languages. I followed a similar approach to the one detailed in this blog post on hierarchical modelling with PyStan. There are two key ideas.\n\nUse a combination of global data as regularization over the detailed, local model. In this case, the global data comes from all the different Java projects. The local model is the specific coupling metrics for one particular project. The effect is to allow each individual project’s slope and intercept values to vary by some amount dictated by the global values.\nWe model this using a Bayesian approach, which means we will condition our likelihood based on the data we are observing, and use that to estimate a posterior distribution. I really like this approach because it forces you to think about your prior distribution (what should the metrics distribution be?), and also because it produces a posterior distribution, and not a single point estimate. A distribution is much more flexible for making inferences than a point estimate (e.g., we could say “set the threshold where &lt; 75% of the probability mass lies”).\n\nThis was also a fun project to do from an open science approach. I used Jupyter as my notebook throughout the project, and my notebook and the paper/presentation are both available."
  },
  {
    "objectID": "posts/2015-07-27-a-field-study-of-technical-debt.html",
    "href": "posts/2015-07-27-a-field-study-of-technical-debt.html",
    "title": "A Field Study of Technical Debt",
    "section": "",
    "text": "Over on the SEI blog, I’ve written up our survey results on technical debt."
  },
  {
    "objectID": "posts/2015-09-25-garbage-in-garbage-out.html",
    "href": "posts/2015-09-25-garbage-in-garbage-out.html",
    "title": "Garbage In, Garbage Out",
    "section": "",
    "text": "My dad had this great cup from one of his vists to COMDEX (ostensibly to keep up with the latest in the tech world, which at the time COMDEX represented). It said “Garbage in, garbage out” (GIGO), and then had the name of some failed software company.\n\n\n\nGigo Mug 2\n\n\nI read a great blog about intermediate targets and over-optimizing what you measure (Hawthorne’s law) and the unintended side effects. Then I watched a presentation on the future of data visualization.\nThe commonality to me is this undesirable focus on the simple over the complex. So a dashboard can in a glance tell you how fast your car is going, which is useful because it maps to two concerns you have as a driver: obeying the speed limit laws, and maximizing your time in the car. I should say, “maps directly”, because as an indicator for these two concerns, speed is pretty much a 1-1 mapping. But consider a car indicator with a much poorer mapping to your concern: the “distance remaining” gauge new cars have. This tells you that based on some model of past driving behavior, you can expect to travel X more miles before the fuel runs out. The problem is this indicator is no longer a simple mapping. You have a (possibly non-linear) model of past behaviour (and no idea how far back the model goes); possibly inaccurate sensors (e.g., depending on temperature, the amount of fuel actually remaining might change); and finally, it is predicting future behavior (you will continue to drive to work tomorrow, and not go on a long distance highway drive).\nIn much the same way I think this fascination with metrics and dashboards confuses construct for concern. If I’m the government CIO, my concern is the value for taxpayer money each project is generating. But the dashboards are probably showing me constructs like estimated time to completion or lines of source code. Furthermore, and this is the data/info vis piece, those constructs are being mapped into visual variables using some arbitrary function. For instance, the decision to turn something from green to red might be based on a simple threshold chosen by an intern.\nIn broad strokes, constructs like source lines of code can, I think, be useful: logarithmically, perhaps, in the sense that a system with 100 thousand lines is more complex than one with only 10 thousand.\nThis typically isn’t how dashboards work, though. Thinking about numbers seems so innately arithmetic (5 is halfway between 1 and 9, not 3) that we cannot comprehend how little the dashboard is telling us. The Japanese lean movement has a nice word that captures what i think needs to happen: genchi genbatsu, “management by walking around”. In a factory, just looking at metrics for production speed and inventory is not the whole picture, and so long ago the Toyota production system creators learned that you had to actually walk the shop floor to see for your own eyes.\nThis is perhaps harder in the non-physical world of software, but I think for most of us we have a sense of project performance innately: are meetings productive? When was the last time you saw a working piece of code? Do you get quick answer to emails? While it is possible to metricize these things, probably it won’t help much more than buttonholing someone in the hallway."
  },
  {
    "objectID": "posts/2017-06-25-Moving-to-UVic.html",
    "href": "posts/2017-06-25-Moving-to-UVic.html",
    "title": "Moving to UVic",
    "section": "",
    "text": "I’m excited to announce I will be taking up a position this fall as a tenure-track faculty member in the Department of Computer Science at the University of Victoria.\nThis is a great opportunity to work with some of the top software engineering faculty in the world, in one of the best cities in the world (although I’m biased, as it is my hometown :). Victoria is at the forefront of the startup scene, just a few hours from Vancouver, Seattle, and direct flights to the Valley (not Abbotsford, the other one).\nIf you are interested in doing research with me please take a look at my ‘prospective students’ page. Uvic, and Canada, welcome people of all backgrounds. See our study permit process, and the federal Express Entry program for post-graduation immigration opportunities.\nI want to thank my colleagues and co-workers at Carnegie Mellon and the Software Engineering Institute for a great four years. I’ve learned a lot about software architecture, large-scale software projects in government agencies, and more US military acronyms than I care to admit. I’ll also really miss Pittsburgh, which has been wonderfully welcoming and a pleasant surprise. It’s easy to see America through a particular perspective these days, but many—most—Americans are awesome and caring people. \nYou can continue to reach me via Twitter, @neilernst, via this web page, or via email, neil@neilernst.net."
  },
  {
    "objectID": "posts/2016-07-19-columbuss-heilmeyer-catechism.html",
    "href": "posts/2016-07-19-columbuss-heilmeyer-catechism.html",
    "title": "Columbus’s Heilmeyer Catechism",
    "section": "",
    "text": "I have no idea if Columbus had to have his “India Expedition” proposal peer-reviewed, but here is my interpretation of it according to the ever-popular Heilmeyer catechism.\n\n\nWhat are you trying to do\nI would like to sail to India and bring back gold and spices for the Crown of Spain.\n\n\nHow is it done today\nCurrently no one has sailed west. Everyone takes the trip east, around the Cape of Good Hope. Most of these people think the world is flat and that heading west would cause us to fall into space.\n\n\nWhat’s new in your approach\nI will head west. I’m pretty sure the Earth is round, and we can reach India from the west in less time\n\n\nWho cares?\nA faster trading route to India, monopolized by our mapping skills, would generate 1 million Real a month for the royal treasury.\n\n\nRisks\nThere is a lot unknown about the middle of the Atlantic, including rumors from the Vikings that some colder land is in between. My math may be off in calculating the circumference of the Earth. I am not a great sailor. We may encounter fierce alien tribes.\n\n\nCost and schedule\nFor 1000 Real we can outfit four boats with sailors, supplies, and weapons (note: of course Columbus would never get all he requested, either!). We plan on a quick 1 year voyage to India, and one more year back.\n\n\nCheckpoints for success\nWe plan to see India after 2000 nautical miles of sailing. While measuring distance at sea is currently impossible, after 3 months we expect to sight land. If not, we will head back."
  },
  {
    "objectID": "posts/2010-04-22-should-we-care-about-evidence-based-software-engineering.html",
    "href": "posts/2010-04-22-should-we-care-about-evidence-based-software-engineering.html",
    "title": "Should we care about evidence-based software engineering?",
    "section": "",
    "text": "Time for some contrariness. The current rage in the academic software research community is evidence-based practice. It’s in popular magazines, desirable in academic publications, and the subject of a new book.\nDoes it matter? On the face, one would say of course. Why would you make decisions ignorant of the facts?  (set aside for now the reality that almost NO decisions in the world are made based on the facts!)\nIt would be nice if software researchers were in a position to present facts to people. In climate science, for example, the facts are pretty clear, and certainly much clearer than corresponding literature in software. That’s why Al Gore, among others, probably sees debates on climate change as pointless. But the utility of model-driven development, among many others, is very much worth debating. I think there are five reasons why we shouldn’t be too concerned about evidence in software development:\n\nThe field with a long history of evidence-based practice, and the most to gain from it, medicine, often doesn’t adopt the recommended practices, or the evidence chosen is irrelevant. Despitehand-washing or checklists being shown (proven?) to be very cost-effective practices to adopt, doctors still leave washrooms without cleaning their hands, and instruments still get left in patients. And in most software projects, there isn’t anything like that sort of liability.\nPeople don’t understand statistical generalization very well. Is that new pill reducing my risk of heart disease 20% more than the other pill, or 20% more than a regimen of Big Macs? Was this experiment done with non-English speakers? There’s a lot more to it than running a few t-tests and calling it a day. See e.g. “Why most published research findings are false” or a series of critiques on fMRI studies.\nSmall results don’t say much. A lot of research is evaluated on small numbers of undergrads or focused on one particular organization (pdf). That evidence is useless to most developers. There is a paucity of in-depth, detailed case studies that generalize to meaningful theories. Personally I am in favour of a moratorium on experimentation in software research until more of these case studies are done. Unfortunately, the lure of the easy number is a Siren-call to reviewers and funding agencies.\nSEMAT to the contrary, there is no good body of software theory that would provide explanatory power to go along with results. Without a theory facts are descriptive; with a theory they can be predictive.\nIt simply isn’t that important. Individuals and organizations do many things which research suggests is downright insane – like embarking on projects without clear requirements, or maintaining 30 year old mainframes – and get by. In fact, anecdotal evidence suggests that many excellent companiesstarted with poor practices, then refactored as needed. Probably, this is because evidence-based software development is a case of premature optimization. For example, despite reams of studies suggesting model-driven development is the way of the future, industrial adoption is underwhelming. Is it because they haven’t read the studies? Or that they evaluated the technology and concluded it wasn’t necessary? As academics, we tend to undervalue the benefit of anecdote and gut feelings. Most of the time this is probably correct, but only if we have evidence to support generalization to common scenarios. Most developers were so burned by the CASE tools of the 1980s that they have no interest in repeating the experience with UML.\n\nI think my final point is that rationality is the exception, rather than the rule, in human behaviour. There’s no reason to lose any much sleep over the fact that industry isn’t following evidence-based software practices.\np.s. I’m a complete hypocrite with respect to experimentation."
  },
  {
    "objectID": "posts/2013-05-30-knowledge-and-complexity.html",
    "href": "posts/2013-05-30-knowledge-and-complexity.html",
    "title": "Knowledge and complexity",
    "section": "",
    "text": "Somewhat inspired by +Rob England, I tried a mapping of Rumsfeldian terminology to Cynefin (yes, i know this predates the SecDef!).\nKnown knowns - either a simple or complicated case. If simple, we do it routinely. E.g. landing an aircraft in good weather.\nKnown unknowns - we have a plan for accommodating it. E.g. landing an aircraft in Edmonton with high crosswinds.\nUnknown unknowns - we are in a complex domain and we have to see how things should work with experiments e.g. edge of envelope flying. One of the things that the Kennedys made clearer for me is how experiments have to be well conceived, in particular, by controlling variables properly (see their SysEng Journal paper).\nUnknown knowns - we didn’t realize we could plan for this but now that we sense it, we can delegate to existing routines, or perhaps adapt to it. That pathway is available but unused. The example would be .. looking through the manual and realizing the system can actually do this (maybe the Apollo 18 case? There they did the exaptation that Snowden often mentions.)\nSnowden would no doubt criticize my limited understanding, but there is some use in seeing how these frameworks co-exist, for me at least.\nUpdate: Dave Snowden replies with a pointer to his HBR article with Cynthia Kurtz in which “knowns” are discussed. Summary: _simple _contexts are the domain of known knowns, complicated contexts are the domain of known unknowns, since experts are required. Unknown unknowns are the domain of complex contexts. Interestingly, they categorize the Apollo 13 case as being in the complex context. In the sense that there was no clear answer, that makes sense, but to me, it also highlighted that idea of unknown knowns: that is, these skilled engineers did “know” the answer (since the astronauts survive), but not consciously. So we could perhaps characterize that as relying on the “expert within”."
  },
  {
    "objectID": "posts/2013-09-11-virtual-conferences.html",
    "href": "posts/2013-09-11-virtual-conferences.html",
    "title": "Virtual Conferences",
    "section": "",
    "text": "Virtual Conferences\nThe virtual conference has many benefits in terms of GHG emission reductions, cost savings, and accessibility. Jon Pipitone and Jorge Aranda co-organized a very small event with me in 2011 around climate change and software. We used Skype and instant messaging to connect climate researchers with software researchers, but my feeling afterwards was that virtual worlds like OpenSim were the way to go. \nIt’s cool to see Crista Lopes has managed a relatively large-scale event."
  },
  {
    "objectID": "posts/2021-04-15-Refsq.html",
    "href": "posts/2021-04-15-Refsq.html",
    "title": "REFSQ Panel session on Open Data and RE Education",
    "section": "",
    "text": "Together with Alessio Ferrari, I organized a panel at the well-regarded conference on Requirements Engineering: Foundation for System Quality, which is a mouthful but really nice working session on RE that has always nicely blended practice and research. It also was the first place to accept one of my papers so I will always have a soft spot for it, and for Essen, industrial city or not.\nThe purpose of the session was to encourage open data packages in the context of RE Education (the aim, I think, is to have subsequent OpenRE tracks at REFSQ change theme). We got excellent submissions and accepted three packages, which we have hosted at the existing repository of the RE Education and Training (REET) workshop.\nAfter the short talks on the packages, we turned to a panel with the theme of “RE in the age of COVID”. Our hope was to collect some experiences from the attendees (40 or so) on how they approached RE education, and RE in general, during the COVID induced shift to online learning. We definitely got that and more generally, I think it was a cathartic session to commiserate and share with others the challenges of the past few terms.\nA few lessons I drew from the discussion:\nParticipants were a bit torn on the need to completely redesign the curriculum vs sticking with the previous content. “Maybe my course was boring and remained boring!” Of course in some cases just getting online was sufficiently challenging to prevent major redesigns. In general projects worked well in both formats. There was some thought that lab exercises worked better, since it was easier to checkin—students were in a fixed location!\nLearner styles or perhaps preferences (since “styles” are not a thing) was something we didn’t have a good handle on. Some students definitely prefer online. But no one had data on who is doing better, and who is doing worse, online vs offline. For example, students seem to appreciate recorded lectures, but mostly to replay/relisten. The downside is it is harder to get questions in a recorded lecture. Even in more normal settings, students are not always sold on flipped classroom. Then there is the problem of video content: should we re-record videos? In the end it’s about making the content relatable and helping them through the struggle with it. Thus there is no substitute or tech fix for the need to demonstrate empathy, use multiple learning techniques, and I suppose the things we know work well in teaching regardless of venue.\nThere was growing recognition that—online and off—bringing some levity and enthusiasm, such as via Serious Games, was critical to keep people engaged in the Youtube and Netflix era. Dan Berry, who has a charismatic personality, suggests we think about being a comic. But of course that will not work for everyone. Even during ‘normal’ lectures, it is not uncommon for 60 students to turn into 3-4 actively participating, 15-20 in class, and some coming merely to sleep.\nIn other settings, participants acknowledged a need to maybe step away from the computer and do a lecture from outdoors, away from disruptions. The 1 year mark of the pandemic led to a let down in formality, with less emphasis on formal backgrounds and acknowledgement that it was ok for it to be weird.\nThere were a few folks who ran hybrid classes, where the university allowed some reduced subset to attend class. The popularity of this depended greatly on the perceived safety level. There were often technical challenges e.g. mic’ing students and sanitizing mic before answering a question, how to get video that made remote participants still feel engaged (e.g., eye contact).\nThe final takeaway was about student well-being. Birgit Penzenstadler, who studies this in her research, emphasized the need to meaningfully check in and get beyond the “how are you doing” question. This is, as she points out, precisely an RE elicitation problem, e.g. “what is the biggest impediment” you are currently facing. We agreed that for most of us, the reality of needing to meaningfully check-in was hitherto unappreciated, and something that is completely independent of learning modality or current global crises. Meaningful checkins are certainly something I will be including in my own teaching practice, online or off (but I hope in person!)."
  },
  {
    "objectID": "posts/2013-01-25-teaching-advanced-software-engineering.html",
    "href": "posts/2013-01-25-teaching-advanced-software-engineering.html",
    "title": "Teaching Advanced Software Engineering",
    "section": "",
    "text": "The course covers software architecture, with a focus on quality attributes, security, and formal methods. I liked the range of material, even though my expertise is limited with formal methods. It is difficult to teach architecture to students in a 3 month time frame, so we expanded using the AOSA textbooks. Students did a presentation for five minutes as a way of exposing them to various different architectures.\nThe other large component of the class is a course project. In this semester they had to build a location-aware, social application. There were great projects including my personal fave, a zombie fighting location-based game.\nMy favorite part of this course, like the third-year course, is seeing how the students approach the project. Some are truly excellent coders and put an enormous amount of effort into the project.\nI introduced a few new lecture topics in addition to the ones pre-existing. I added a topic on Service Orientation and SOA, important trend in particular in enterprise architecture; a new topic on REST, which was well connected to the project; and a topic on agility and architecture, based in part on the book by Dean Leffingwell, Agile Requirements. I thought all of these were useful, although they tend to be less easily tested than e.g. model checking, so perhaps students are just forgetting them. I even mentioned CMMI!"
  },
  {
    "objectID": "posts/2013-01-25-teaching-advanced-software-engineering.html#material",
    "href": "posts/2013-01-25-teaching-advanced-software-engineering.html#material",
    "title": "Teaching Advanced Software Engineering",
    "section": "",
    "text": "The course covers software architecture, with a focus on quality attributes, security, and formal methods. I liked the range of material, even though my expertise is limited with formal methods. It is difficult to teach architecture to students in a 3 month time frame, so we expanded using the AOSA textbooks. Students did a presentation for five minutes as a way of exposing them to various different architectures.\nThe other large component of the class is a course project. In this semester they had to build a location-aware, social application. There were great projects including my personal fave, a zombie fighting location-based game.\nMy favorite part of this course, like the third-year course, is seeing how the students approach the project. Some are truly excellent coders and put an enormous amount of effort into the project.\nI introduced a few new lecture topics in addition to the ones pre-existing. I added a topic on Service Orientation and SOA, important trend in particular in enterprise architecture; a new topic on REST, which was well connected to the project; and a topic on agility and architecture, based in part on the book by Dean Leffingwell, Agile Requirements. I thought all of these were useful, although they tend to be less easily tested than e.g. model checking, so perhaps students are just forgetting them. I even mentioned CMMI!"
  },
  {
    "objectID": "posts/2013-01-25-teaching-advanced-software-engineering.html#overall",
    "href": "posts/2013-01-25-teaching-advanced-software-engineering.html#overall",
    "title": "Teaching Advanced Software Engineering",
    "section": "Overall",
    "text": "Overall\nI feel that these types of courses in SE should be more about reflective apprenticeship than the lecture and project model. In other words, there should be more focus on feedback about the way in which students do design, more experiential learning, and less memorization of specific techniques such as formal methods (which should really be in a separate course, in my opinion). Mark Guzdial called this reflective apprenticeship and points to the work of Donald Schön.\nA parallel might be drawn with the way law schools operate. If you want to learn about how one practices law, argues cases, etc., you hire experienced practitioners as adjunct faculty. There seems to me to be a real difference between the skills of an academic SE faculty member and a person who has spent years building high-availability, mission critical software. There are a few of the latter at UBC, such as Philippe Kruchten, but in general it is exceedingly difficult for them to be hired without academic credentials. Not to mention the increasingly large salary gap between industrial SE and academic SE.\nThe other thing I disliked is that it seemed to me that a few students hid out during the project, latching on remora-like to their more capable teammates to secure a good mark with no work. It irritates me to pass students who are not able to write code (not good code, or even mediocre code - just not write code! See Fizzbuzz). It is very difficult to (defensibly) identify these people, however. One technique which I should have used is to ask questions of the indifividual students during their final demos. This would help to identify who actually knows what the heck is going on."
  },
  {
    "objectID": "posts/2013-01-25-teaching-advanced-software-engineering.html#academic-dishonesty-and-software-engineering",
    "href": "posts/2013-01-25-teaching-advanced-software-engineering.html#academic-dishonesty-and-software-engineering",
    "title": "Teaching Advanced Software Engineering",
    "section": "Academic dishonesty and software engineering",
    "text": "Academic dishonesty and software engineering\nOn the one hand we cannot prohibit collaboration and code re-use: these are fundamental practices in software engineering. On the other hand, we need to assess the student’s actual contribution. I had a few interesting cases that suggest our pollicies in this area need more attention. 1. One group used a sample Ruby on Rails project to bootstrap their application. It came with most of the controllers they needed. They then customized the UI and logic to implement the functionality (poorly). 2. Another team hired a third-party designer to do custom artwork for the project (which looked fantastic). 3. A different team had a friend with web design expertise work on the CSS for the project. 4. Several teams used Twitter’s Bootstrap UI library or JqueryUI to simplify their efforts on the design end. 5. Many groups used third-party libraries to simplify their life, like JQuery, Rails, image libraries, etc.\nObviously, most of these are exactly what would happen in industry. On the other hand, it definitely gains one an advantage. The Twitter Bootstrap apps all looked an order of magnitude better than the custom apps.\nMy principle was the remixing and reuse was fine, as long as it was properly acknowledged. In the design case, we could try to discount that aspect of the UI in the marking. But it is almost certainly the case that some groups did NOT acknowledge their use of other people’s IP, and yet benefited from it. I don’t have a good solution to the problem of detecting code reuse. And furthermore, the burden of proof is pretty high to call something cheating, and requires more than a gut feeling or a commit to Github that touched hundreds of files at once (i.e. a bulk commit of 3rd party code)."
  },
  {
    "objectID": "posts/2013-01-25-teaching-advanced-software-engineering.html#it-role",
    "href": "posts/2013-01-25-teaching-advanced-software-engineering.html#it-role",
    "title": "Teaching Advanced Software Engineering",
    "section": "IT role",
    "text": "IT role\nOne of the things which I think will only become more prevalent is the use of third-party services to manage the course. In the past, students would use CS department machines and servers to do their assignments, a CS database server, and store code on the department subversion or IBM RTC servers.\nThis semester I don’t think we used a single department resource, save for email (and that only because I was forced to for privacy reasons) and the course webpage. Class discussions took place on Piazza.com; code and issues were managed with Github, and students nearly always have their own laptops and Android devices (there was not a single group that chose iOS, incidentally, although nearly half the class has Macbooks. I think the 99$ fee is a real stumbling block - that and Objective-C).\nI did not get any support or materiel from the department, apart from the classroom and photocopier. I could just as easily have run this course from my home. So what should the IT section do? They could manage Github for me (they were extremely reluctant to do this, and very hesitant about even installing Bugzilla, apparently). They could provide more AV services to record classes. They could manage virtual machines for me, so that each student could install the same setup – things like Puppet and Vagrant will be key in the coming years.\nFinally, the UBC wireless infrastructure is truly terrible. You get better wifi at the Starbucks. Latency between two machines in my office was 200ms! The connection is constantly dropping or extremely slow, such that even demos are affected by the web performance."
  },
  {
    "objectID": "posts/2013-01-25-teaching-advanced-software-engineering.html#student-perceptions",
    "href": "posts/2013-01-25-teaching-advanced-software-engineering.html#student-perceptions",
    "title": "Teaching Advanced Software Engineering",
    "section": "Student perceptions",
    "text": "Student perceptions\nIn an unscientific survey, I asked the following questions:\n1. How could the TAs and myself improve your experience?\nStudents were either positive (but they had names attached to their responses, so that isn’t unexpected) or asked for more help. One of the big challenges they face is sorting out silly configuration problems. They would like more advice on design choices as well. I think this is a real opportunity to make the project more like an apprenticeship model, a la Software Craftsmanship: take some senior developers, get them to do an hour of code review, an hour of design feedback, etc. And there seem to be many companies eager to help out (and recruit) for whom this might be doable.The other issue was that due to 4) below, TAs and myself often did not know much about the technology (e.g., Microsoft’s C#/Azure platforms). However, this is definitely a learning objective in the course. Admittedly in industry one would often be able to ask senior devs these questions. However, the ability to track these answers down is invaluable, I feel.\n2. Were the AOSA readings useful?\nMost students responded that they appreciated the opportunity to present to a large audience. But the overall lessons of the architecture in these systems was lost on them, because it did not have a lot of relevance to the project, which consumed the majority of the time. Asking exam questions was difficult, as there was a lot of material that would have to be studied. I think I would keep this module but be more strict about the time limit (5mins) and give some introductory examples/prep before hand.\n3. Did Github work for you?\nStudents loved Github. Egit was less good (and personally I find it less usable than the command line). A major improvement over RTC.\n4. Was the freedom to choose language good or bad?\nMost students loved this aspect as well. In the past the project, worth 40% of the course, has been in e.g. Java+Tomcat for everyone. Feedback here indicated that main problems were finding team members with similar interests (in, e.g. RoR), getting help from TAs, and a possible penalty on the final, where the code snippets are in Java.\n5. What annoyed you about the project?\nUnsurprisingly, most complaints were about the time it took - one student spent 80 hours over two weekends on what was, however, a really cool UI - and the vagaries of group work with fellow team members, some of whom get sick, abandon their teammates, or simply are not good at programming. Students would appreciate more help on scoping the project, and getting the thing started earlier. We tried to address this by insisting on an early ‘project idea’ review in the first 3 weeks, and by doing a 30 minute design review midway. However, some people have to learn the hard way, and ultimately, we are constrained by how many teams there are - 27 in this case. Multiply that by 30mins and you can see the magnitude of the challenge. I had 3 TAs to help, but that is still a ton of work. And I think students got frustrated, since they see a 1-1 interaction, not 27-1 that I see."
  },
  {
    "objectID": "posts/2015-02-23-thoughts-from-a-codefest.html",
    "href": "posts/2015-02-23-thoughts-from-a-codefest.html",
    "title": "Thoughts from a CodeFest",
    "section": "",
    "text": "This past weekend was the Steel City Codefest. The idea is that community non-profits present some problem for which an “app” would help them, and coders spend 24 hours coming up with some solution. It was a lot of fun. site-urlYou can see our team’s solution at http://citipark.herokuapp.com. –&gt; Our challenge was to create an easier way for people to find the city of Pittsburgh’s GrubUp food program, which offers free lunch and breakfast at 80+ sites around the city in the summer (sadly, a lot of Pittsburgh youth are food insecure).\nWe didn’t win the challenge, but I learned a lot on the way.\nWe created tons of  technical debt : code clones, code comments, no testing, no design. It was code as fast as possible, get it working, fix the obvious user facing bugs. We shipped. But even during that 24h span the design hit us, as it became harder to change things since logic and UI were wrapped together. Even something as trivial as renaming a media folder became a massive headache. We had no tests, so any change had to be “tested” by running the app and running through a few scenarios. Error handling was likewise left for later work, so if faulty input was entered the whole thing crashed.\nIt took a long time simply to do infrastructure setup: what Github repository, what web host, what database, how do we communicate together. Part of it was this was only my 2nd time building a node application, so I was unfamiliar with its internal expectations and capabilities. Things like “don’t send headers twice” caused problems for me that a more experienced developer would not have had. In a 24h period this stuff needs to be like riding a bike, so deciding on a framework that I had little experience in was costly. It’s like going to a marathon without having trained at all.\nWe were three people: two coders and a designer/QA person. Three was the minimum, and it really wasn’t enough. There were tasks like entering data into the database (the Citiparks staff provided excel spreadsheets) that took me a few hours but had zero payoff. In a codefest, data quality is not a factor in the judging (the judges don’t come from the clients). In an enterprise situation, the data is probably as important as anything else, but here it was wasted effort, and sample data would have worked fine.\nWe had somewhat of an idea how things would work, but wireframing it beforehand, and being much clearer about what steps were necessary, would have been better (you could not write code before, but this sort of sketching was allowed). A simple design plan and backlog would have been easier to work off, and help to resist the temptation to simply start hacking away. A number of times I would push back from the table, and say to myself “do I even need to do this?”\nWriting code this way is a great way to learn these lessons. I have a number of academic publications about finding requirements, for example, but it is only when you do it yourself that you realize how much is lost between the quick IM conversations you have with teammates and the actual issue tracker. I do wonder, however, if these 24h codefests promote ‘code first’ over the value of design. For example, my sense is that a lot of what we did simply wouldn’t work in an enterprise environment: there are design guidelines, authentication, security, data integration, lifecycle maintenance concerns, none of which you have the luxury to spend much time with. The cool thing about the Steel City event, however, is that the organizers do make a series of $10k grants available, in order to take the app to a more integrated and polished version.\nIt was a great event - very well organized, with great food and volunteers. And the Citiparks staff were amazing, sending their director and deputy director to do user testing at 7pm Saturday, and bringing amazing treats for us twice during the event. It also focused on an underserved area, in my view: social justice and not-for-profits. Many have quite simple needs, that in many cases amount to adding data to a Google Map, but even that is beyond their budgets."
  },
  {
    "objectID": "posts/2013-10-24-configuring-sonar-with-maven-on-mac.html",
    "href": "posts/2013-10-24-configuring-sonar-with-maven-on-mac.html",
    "title": "Configuring SONAR with Maven on Mac",
    "section": "",
    "text": "I had this issue a few times:\n\nyou get SONAR installed and the web client working fine (e.g. you can go to http://localhost:9000 and see the dashboard).\nyou have a project to analyze with a Maven POM, to which you add the sonar target as described here.\nyou start the Maven run and it returns in short order saying:\n\nCan not execute SonarQube analysis: Unable to execute Sonar: Fail to download [http://localhost:9000/api/server].\nTurns out for some reason this is a problem with the default Ruby install on OSX. The workaround is to use JRuby instead of Ruby, best done with RVM, e.g. rvm use jruby. Someone mentioned this online, and I cannot find the post now, but thanks.\nI use Sonar with Homebrew, by the way, which has its log files at /usr/local/Cellar/sonar/&lt;version&gt;/libexec/log/sonar.log."
  },
  {
    "objectID": "posts/2015-01-06-measuring-programmer-productivity-is-futile.html",
    "href": "posts/2015-01-06-measuring-programmer-productivity-is-futile.html",
    "title": "Measuring programmer productivity is futile.",
    "section": "",
    "text": "(I’ve typically posted long-form entries but so infrequently … )\nThe arguments and debates about 10x productivity in “programmers” rage on (this time to defend/reject H1B visas). This debate is doomed to never be concluded. I think the reason why is nicely captured in Andrew Gelman’s post on p-values: they work best when noise is low and signal is high, something which can never be the case when we talk about productivity. As he says,\n\nIf we can’t trust p-values, does experimental science involving human variation just have to start over?\n\nGiven a random sample of (let’s say) Microsoft software developers, can you devise a test that would show the statistical differences? Are you convinced you would have high power? A big effect size? One person online (via HackerNews) says it is about tool competence. But the recent Latex/Word study leaves me doubting even that conclusion (although I have trouble with that study too, which just reinforces my overall point).\nMore importantly, I think this calls into question almost any controlled experiment in software engineering. Short of replicated results, I’m skeptical the information content is very high. Instead, I would like more qualitative research. Why do people say there is this difference? What traits are important? Can they be taught? How do we share productivity improvements? These questions seem much more important than trying to attach a p-value to whether one group is better than another."
  },
  {
    "objectID": "posts/2016-09-08-day-hikes.html",
    "href": "posts/2016-09-08-day-hikes.html",
    "title": "Day Hikes",
    "section": "",
    "text": "A list of long, high vertical day hikes I have done and wish to do. I think looking back the most common theme to all of them was “bring more water”.\n\n\n\nHike Name\nLength\nElevation Gain\nElevation\nNotes\n\n\n\n\nBlack Tusk\n29km/18mi\n1740 m/5700’\n7600’\nHighly exposed last section up remaining volcanic core. See details\n\n\nLions\n16km/10mi\n1280m/4200’\n5427’\nI remember when we did it in 2001 or so there being little to no trail markers. Trail page\n\n\nTriple Crown (Finlayson, Work, Gowlland Range )\n? Maybe 10mi/16km\n? Probably around 1000m/3200’\n1375’\nI couldn’t find details on this, but the gist is to hike up Finlayson, go down the backside, then back up along the Gowlland Tod ridge above the inlet, then up Mt Work at the end.\n\n\nHalf Dome\n26km/16mi\n1450m/4800’\n8839’\nCables! Now need permits to go. Trail page\n\n\nMt St Helens\n16km/10mi\n1370m/4500’\n8366’\nPermit needed. Painful boulder climbing and loose scree from middle to end. Insanely exposed rim of crater. Trail page\n\n\nGolden Ears\n24km/15mi\n1500m/4900’\n5630’\nSome freaking jackrabbit passed us going up and was heading back down before we summited. Even in June had plenty of snow that made the top risky without ice axes and/or crampons. Trail page\n\n\nMt Thar\nNo idea. Took about 6 hrs.\nYak Mtn is listed as 1640’ for prominence, so I’d guess no more than 1200’ for Thar.\nYak: 6693’\nTrip report This one is in 103 Hikes in the SW BC, highly recommended.\n\n\nMonte Bondone, Trentino, IT\nAbout 12 hours.\nTrento centro is 636’, so nearly 6500’ of elevation gain (seems high to me)…\n7150’\nI started in Vela where my flat was. The Italian Alpine club chapter - S.A.T. - has a good trails site and maintains the helpful markers. You can take a cable car back to the river from Sopramonte to shave a few minutes off.\n\n\nMt San Jacinto\n30km/19mi\n1700m/5600’\n10,833’\nTBD! Trail page"
  },
  {
    "objectID": "posts/2013-03-02-obtaining-a-pennsylvania-drivers-licence-with-an-h1-b.html",
    "href": "posts/2013-03-02-obtaining-a-pennsylvania-drivers-licence-with-an-h1-b.html",
    "title": "Obtaining a Pennsylvania Driver’s Licence with an H1-B",
    "section": "",
    "text": "In case this helps other people:\nPennDOT rules on what paperwork is needed can be found here. In addition, keep in mind the following:\n\nWe needed a letter from my employer, I94+passports, old licences, 2 proofs of residence (lease+bills), and a rejection letter from Social Security for the SSN (for my wife) and a letter with the number on it for me (haven’t got the physical card yet).\nIf you have a H1-B, and your spouse has an H4, you will need to go with your spouse if s/he is getting a licence as well - you can’t go separately.\nPennDOT does not take cheques drawn on foreign banks, only US banks. Fortunately you can get money orders easily at grocery stores. There is a Giant Eagle that does this near the Penn Hills licence centre.\nStaff are pleasant but extremely over-worked, so be patient. Downtown Pittsburgh was less busy during the week than Penn Hills on the weekend."
  },
  {
    "objectID": "posts/2013-10-16-the-circle-a-novel.html",
    "href": "posts/2013-10-16-the-circle-a-novel.html",
    "title": "The Circle, a novel",
    "section": "",
    "text": "The Circle is a novel about the tech/social networking industry, where fictional company the Circle plays the role of Twitter, Facebook and Google combined. The topic is certainly ripe for the satirizing, but I didn’t think Eggers pulled it off very adroitly. Either he was going for the brutal, over the top parody like Jonathan Swift’s _A Modest Proposal, _or he was writing it very quickly and perhaps in anger. The characters felt a little flat and one-dimensional (Mae for example was unbelievably naive) and the conspiracy (or ‘logical extension’ perhaps) was hard to believe—Americans are fiercely proud of being independent and private, so the idea that they would willingly join in with mandatory Circle membership felt off. \nSome points I thought were well made. For example, the skewering of the “campus culture” of tech companies which privileges the already-privileged while the drivers of the busses and local inhabitants are worse off. The technocrats who think technology presents a simple solution to all problems (witness the Gates Foundation and educational testing, for example) are an unfortunate reality today. Parts of the book raised good and thought-provoking questions about understanding social media tradeoffs. Some of the reasons why privacy is important are really poorly outlined (but perhaps the question is wrong on its face—why should I justify my need for privacy?). There really are things that technology has improved dramatically—every time I use Skype with my parents I realize this. Tracking my friends on Facebook is a nice thing to do and brings them more into my life as well. \nI appreciated that aspect of the novel, and it has given me a new perspective on being a ‘user’/‘product’ of social media tools. Overall, this is a topic that cries out for a sustained and subtle approach and I felt The Circle was too facile and, for the Valley cognoscenti who most need it, too easy to dismiss. By the way, there is a certain irony in posting my thoughts about this novel online, but doing so on my own blog feels somewhat different. I hope."
  },
  {
    "objectID": "posts/2021-06-03-The-Scientific-Method-2021-edition.html",
    "href": "posts/2021-06-03-The-Scientific-Method-2021-edition.html",
    "title": "The Scientific Method 2021 edition",
    "section": "",
    "text": "The typical Science workflow is something like\nA - Related work: build a Prior about a real world problem, like pulsar formation\nB - Fieldwork: Collect data about that problem in the ‘field’\nC - Model: Build a model of the problem\nD - Posterior: Generate a posterior/data output\nE - Analyze: draw inferences about A, updating the prior if necessary.\nWe can have several types of problems - “debt” - in this process.\nNote that in A/B, we are in traditional science. This is the stuff you would learn in Astro 200 - how planets form, how to take readings, etc.\nI want to focus on C, as an issue of scientific technical debt. I think a lot of challenges have to do with understanding the tradeoff between the scientific challenges in A/B/E, and the engineering focused challenges in C and D. Ultilatemly to do good science - to design vaccines, to predict climate adaptation approaches, to better understand pulsars - we need to have all of these phases working efficiently. Since I know about C that’s where I’ll focus."
  },
  {
    "objectID": "posts/2021-06-03-The-Scientific-Method-2021-edition.html#making-models-accessible",
    "href": "posts/2021-06-03-The-Scientific-Method-2021-edition.html#making-models-accessible",
    "title": "The Scientific Method 2021 edition",
    "section": "Making Models Accessible",
    "text": "Making Models Accessible\nThere are two dimensions (or more) to this question. The first is about using models and building them; the second is about querying them."
  },
  {
    "objectID": "posts/2021-06-03-The-Scientific-Method-2021-edition.html#model-usability",
    "href": "posts/2021-06-03-The-Scientific-Method-2021-edition.html#model-usability",
    "title": "The Scientific Method 2021 edition",
    "section": "Model Usability",
    "text": "Model Usability\nWe now see tons of tools that help with modelling. Here are some illustrative examples\n\nFortran, in Global Climate models\nPython, in Ralph Evin’s building sims\nAstropy\nCommercial: Tableau, RStudio, Metabase, https://core.hash.ai/@hash/wildfires-regrowth/9.8.0 are moving from building dashboards and visualizations into more complex modelling support. But like dashboards, the challenge is less about using bars vs lines, and more about the A/B and E parts: what problems do I need to learn about.\n\nOne challenge in the move to more complex models is of course the inflection points: the places where the models fail to capture the real world. It is trivial to build a predator-prey model; to build one that accurately captures the dynamics of wolf/elk dynamics in the Mackenzie valley is entirely different, and probably the validity of the model is only understandable by maybe 100 people in the world. Increasingly the challenge in peer review is not about (or not just about) the problem’s relevance or significance, but whether the data and model support the claim. Technical debt in science is a massive concern if we are going to rely on large, difficult to verify datasets for our claims.\nHow easy it is to build the model:\n\nShow examples of RStan, Fortran, Hash as dealing with the problem of “building the model”"
  },
  {
    "objectID": "posts/2021-06-03-The-Scientific-Method-2021-edition.html#accessing-model-outputs-digital-twins",
    "href": "posts/2021-06-03-The-Scientific-Method-2021-edition.html#accessing-model-outputs-digital-twins",
    "title": "The Scientific Method 2021 edition",
    "section": "Accessing Model Outputs: Digital Twins",
    "text": "Accessing Model Outputs: Digital Twins\nBryan Lawrence blog post\nThe idea that in SKA you might not get raw data"
  },
  {
    "objectID": "posts/2015-12-07-requirements-agile-and-finding-errors.html",
    "href": "posts/2015-12-07-requirements-agile-and-finding-errors.html",
    "title": "Requirements, Agile, and Finding Errors",
    "section": "",
    "text": "It’s a long held view in the requirements engineering (RE) community that “if only we could do RE better, software development would be cheaper”. Here ‘doing RE better’ means that your requirements document adheres to some quality standard such as IEEE 830. For example, none of the requirements are ambiguous.\nOne justification is that, based on (very few) studies in the late 80s, requirements errors cost a lot more to fix in test/production than when they are incurred. For instance, if I tell a subcontractor she has a 100 kilobyte message size limit, and I really meant 100 kilobits, fixing that problem after she has delivered the subcomponent will be expensive. This seems obvious. But two problems emerge. 1) Why does she have to wait so long to integrate the subcomponent? 2) how many of these problems are there? Granted it is cheaper to fix that particular error in the requirements/system engineering phase, how much money should we spend to find these errors at that point? [1]\nAn interesting early experiment on this is described in Davis, 1989, “Identification of errors in software requirements through use of automated requirements tools”, Information and Software Technology 31(9) p472–476. In an example of an experiment we see very rarely these days, his team were given sufficient funds to have three automated requirements quality tools applied to a large software requirements specification for the US Army (200,000 pages!). The tools were able to find several hundred errors in the spec, including errors of inconsistency. Yay, the tools worked! But….\nThe program had decided to go ahead and build their (Cobol) system before the automated analysis. The developers on the program didn’t care much about the findings. 80 of the 220 modules were not detectable in the final system (meaning, presumably, they were either merged or omitted altogether). Davis did some post-delivery follow-up, showing that the modules with greater numbers of requirements problems had a significantly greater number of post-release defects. But whether the two are causally related is hard to say (those modules may simply be more complex in general, so both requirements and code are harder to get right).\nWhat I conclude from this is that finding errors of the sort they did, e.g.,\n\nPROBLEM: the referenced table directs that PART_NO be moved from the WORK_ORDER_FILE to the WORK_TASK_FILE. Available fields in the WORK_TASK_FILE include PART_NO_FiELD_PART and PART_NO_FIELD_TASK.\nCHOICE: We assume that PART NO FIELD_TASK is the proper destination.\n\nare ultimately of zero value to document. As a result, finding problems with them, automated or otherwise, is also of no value. Of course we know all this from the past 20 years of the agile movement, but it is interesting to see it in action. I think that (in 1989 certainly) this was excusable, as the program managers had no good sense of what made software special. The level of detail the design describes, down to field names and dependencies, is better suited to the Apollo program, where they prescribe how tightly to turn bolts, label each individual bolt, etc. Which makes sense in a safety critical dynamic environment, but not a lot of sense in an office logistics tool.\n\nGoing Forward\nA term I loathe but seems better than “Future Work”. I’ve worked a lot on automated requirements tools like PSL/PSA or SREM, so where should we head with automated tooling for requirements?\nThere is a lot of empirical evidence that simple, easily integrated process patterns such as requirements goals and scenarios lead to higher quality requirements. Intel, for example, are strong believers in training staff in writing good requirements (although notice their domain is also hardware-oriented and mistakes are costly). Even in agile settings I believe there are big improvements to be gained in writing better user stories (e.g., how to create the “Magic Backlog” described in Rebecca Wirfs-Brock’s EuroPLoP 2015 paper).\nFurthermore, we are seeing more and more use of machine learning to flag requirements problems. For example, at Daimler they have simple detectors for checking requirements. And at Rolls-Royce, based on simple training exercises, they label requirements based on potential risk, combining uncertainty, change impact and cost into an index. All of these types of tools integrate will into a developer analytics approach, able to populate dashboards and flag things unobtrusively (compared with the cost of writing requirements formally).\nLike with any analytics techniques, which ones to apply is situation-specific. Small companies doing the same things in well-understood domains won’t need much, if any requirements analysis. I think there is a lot of room for intelligent augmentation of what makes a good requirement, that facilities conversations and discovery of uncertainty, that automates the repeated and boring tasks (if you cannot possibly avoid creating a 2000 page document …). And in specialized domains, we are moving to a world where more and more of the analysis can be done in models, to verify timing requirements, guarantee that software partitions hold, and so on. Here the line between ‘requirement’ and ‘design solution’ is blurry, because requirements at one level become design solutions at the next level. A mature requirements practice would leverage this to enable experimentation and prototyping in silico, as it were, finding design problems before releasing products or fabricating chips.\n\n\nFinding Defect Leakage\nA major goal for large programs is to reduce defect leakage, the number of bugs that make it to production (to put it more precisely, reduce the number of critical bugs that make it to production). It seems to me there are at least four complementary approaches to this issue:\n\nWe could do this manually, and insist on writing good requirements using checklists, training, inspection, etc.\nWe could use formal methods, on well-formed architectural models, looking for very specific rule violations (safety, security, performance);\nWe could apply machine learning tools on past artifacts and try to leverage experience to predict problems. Not every requirement is equally important (obvious but not always followed).\nWe could design a process that accepted the inevitability of change and made it not only possible, but desirable to change design and requirements in response to new knowledge.\n\nFor the automated tools, I have this quick list of principles. Much like software analytics in general:\n\nDon’t make life worse. Developers should not dread having to do this. That said, an ounce of pain is worth a pound of pleasure.\nWork with existing tools like Doors, Jira and Excel. Your Eclipse plugin does not count.\nDon’t mandate new or complex languages or tools for requirements. We can barely get engineers to write requirements in natural language as it is.\nPrefer lightweight, high value checks over complex, theoretically appealing ones. Socialize people to the value of checking anything before insisting on the complex stuff.\nIntegrate with existing dashboards like Shipshape or SonarQube. These tools have good plugin frameworks and already integrate with many build and CI servers.\nFacilitate conversations and early delivery of results. Remember that requirements engineering is the start of a conversation that gets us to a valuable solution. It is never an end in itself. In very few domains does assuming requirements won’t change get you anywhere.\n\n\n\nAnd Basili and Weiss’s 1981 study on the A7 program’s change requests and requirements suggest a power-law distribution to the most costly (e.g., &gt; 1 person-month of effort) changes.  ↩︎"
  },
  {
    "objectID": "posts/2011-07-27-writing-complex-latex-documents-with-scrivener-2-1-and-multimd-3.html",
    "href": "posts/2011-07-27-writing-complex-latex-documents-with-scrivener-2-1-and-multimd-3.html",
    "title": "Writing Complex Latex Documents with Scrivener 2.1 and MultiMarkDown 3",
    "section": "",
    "text": "I have another post that discusses my approach to writing my thesis using Scrivener. It’s out of date now because I transitioned to MultiMarkdown 3 (MMD3).\nThe Latex support in MMD3 is much simpler than the previous version. Instead of complicated XSLT transforms from the HTML formatted Markdown output, the new approach is to transition from the Markdown directly to Latex. It makes customizing the output much simpler - no more editing XSLT files. In the following, I assume you have a Scrivener document that contains the body of your work (e.g., Introduction, Related Work, Observations, Conclusions). Here’s how to get started:\n\nScrivener still ships with MMD2, so you will need to install MMD3 on your Mac. Fortunately this is straightforward. Go to the download page and download MultiMarkdown-Mac-3.0.1.pkg.zip and MultiMarkdown-Support-Mac-3.0.1.pkg.zip (as of July 2011). The support files will seamlessly integrate MMD3 with Scrivener. I’m not sure how easy it is to revert, however, so be careful  (update: pretty easy - seethis note). I do think it is ultimately easier to work with MMD3.\nNow we need to add custom metadata to Scrivener to add the ancillary files for MMD3. I’ve found the easiest approach to be adding a Meta-Data text document as the first document in your Scrivener project (right-click the top folder in the Binder, Add-&gt; New Text). Now we will tell MMD3 where to find the extra files for our Latex output. Here’s what mine looks like:\n\nBase Header Level: 2 Bibtex: IEEEabrv,../../bibtex/thesis-new Latex footer: ut-thesis-end Bibliostyle: plainnat-nourl Title: My Big Thesis Author: Neil Alexander Ernst Latex input: ut-thesis-begin\nOrder matters here. See Fletcher’s guide on metadata in MMD3.\nBase header level is telling MMD3 that we want to create Chapters for each first-level Scrivener folder (I think Base level 1 is “Part”). Bibtex is the location of the bibtex files, relative to where we will run the “latex” or “pdflatex” commands. Latex footer will be inserted at the end of the last piece of your Scrivener file using the Latex command . There is also Latex header, but as we will see that doesn’t work well. The next command, Bibliostyle, will define the bibliography style for use with Bibtex. Title and Author are obvious, and I finish with Latex input. This is the beginning Latex of my thesis document, including packages, newly defined commands, etc. Now, because MMD3 will turn the metadata entries into variables in Latex, it is important that the input come after the definition of the title and author (otherwise there is an error). This is also why I avoid the use of the Latex header metadata.\nNow it is up to you to define what document class etc. to use for your document: MMD3, nicely, will just stick whatever is in input/footer/header into the appropriate place in the Latex file. There are some nice pre-defined input sections Fletcher Penney created, that you can download as well on the Github site.\nNow in Scrivener, compile your document using the File-&gt;Compile.. and setting “Compile For…” at the bottom to “Multimarkdown-&gt;Latex”. Note that it is important to disable conversion of two hyphens to an en-dash, otherwise HTML comments don’t work, and you cannot escape the Latex properly.\nNote: to escape Latex, surround the Latex (e.g., tables, math) with HTML comments (). The most useful MMD features, for me, are lists, which are just numbers or bullets (see the Markdown syntax guide). Much simpler than the cumbersome \\begin{itemize} syntax.\nTo use citations with MMD3, you can use the [#citename;] or [#citename] syntax for or Natbib commands, respectively. You can also do MMD footnotes with [^foot1] and [^foot1]:Footnote text. I haven’t used any other advanced features of Markdown. The number one wish I have is for easy syntax, but I don’t know how to do it (edit: see the helpful post here). MMD3 automatically creates a after each section heading, based on the section name with no spaces.\nI don’t mind writing raw Latex: emacs+Auctex+refTex makes it pretty painless. But I found, for my 60,000+ word document, that it was much easier to do revision and editing in Scrivener: moving sections around, for example. It also uses Mac native spell-check which is pretty nice (Emacs’s spelling I find clunky and slow).\nMy files for reference:\n\nThesis preamble\nThesis end section\nSubset of MMD output\nSubset of Latex output"
  },
  {
    "objectID": "posts/2011-10-25-what-i-learned-at-uoft.html",
    "href": "posts/2011-10-25-what-i-learned-at-uoft.html",
    "title": "What I learned at UofT",
    "section": "",
    "text": "My dissertation is nearing approval (touch wood) and I have started a new position as a Post-doctoral Research Fellow and lecturer at UBC. I wanted to summarize my experiences in grad school as a reflective exercise. I often found I got down on myself during the process: it is an incredible challenge to acquire a research Ph.D. at one of the top-10 computer science schools in the world. I’m extremely proud of my past selfs for persevering and allowing 2011 Neil to reap the reward, as it were. ’Cause 2006-2008 Neils put up with a lot of sh*t.\nThese are all things I knew nothing about when I arrived for my PhD in 2004:\nLanguages and Tools\n\nPython (matplotlib, numpy, networkx)\nLisp (SBCL and Clozure)\nGit and SVN\nTwitter, Facebook, Wordpress\nMendeley\nLatex + Scrivener + MMD3\nFlash / Flex\nSqlite\nRuby/RSpec/Rails/Gems\n\nFrameworks\n\nMDE with Eclipse and GMF\nLogic programming with ATMS\n\nTheories\n\nKnowledge representation\nPropositional logic\nNon-monotonic logic\nLatent Dirichlet Allocation\nAgile software development\n\nMiscellaneous\n\nA smattering of Italian (via ferrate means “iron ways”).\nThe importance of good coffee.\nHow to change a diaper at 4am without turning on the lights.\nFriends: It’s somewhat trite to say that it was the people you met who you will remember, but that’s true. I think one of the most enjoyable things about moving on to a new experience is the idea that there will be all of these people you will call friends in five years, of whom you know nothing now.\nHow to prepare and defend a 60,000 word opus starting with no knowledge of the area, no relevant background skills, and little to no published work. In that context seven years seems about right.\n\nThanks to my wife and family for getting me to this point. They found the right combination of “why are you doing this again” and “you can do it”."
  },
  {
    "objectID": "posts/2015-01-15-the-gap-between-user-requirements-and-software-capabilities-as-technical-debt.html",
    "href": "posts/2015-01-15-the-gap-between-user-requirements-and-software-capabilities-as-technical-debt.html",
    "title": "The Gap Between User Requirements and Software Capabilities as Technical Debt",
    "section": "",
    "text": "One of my favorite graphics is from Al Davis, in 1988. Aside: it is depressing how often we re-invent the wheel in this business.\n\n\n\nAl Davis requirements growth\n\n\nThe nice thing is how one can map various software development concepts to parts of the diagram. I actually think there is another thing you can grab there. Well, two things. One, the environment is not captured in this picture, but only user needs and the specification. In most cases (maybe this is what wasn’t clear in 1988) the user requirements are constrained by the environment, that is itself changing. This is part of our re-definition of the requirements problem of Zave and Jackson.\nTwo, I think you can use this to show how the rate of growth in the gap between needs and system (what Davis calls “inappropriateness”, the shaded area) is also an issue. I think this captures the technical debt problem more succinctly. You will see a growth if, for example, you chose a technology solution that constrains your use of web browser (eg. ActiveX controls mandating IE8). That forces your red line (development/specification/software) to grow slower. Now the question becomes, at what point do you refactor/reengineer so that the rate of adaptability (the slope) increases again?\n(I don’t actually know where I got this – maybe Steve Easterbrook, he likes Comic Sans a LOT – or the original source for this but maybe here.)"
  },
  {
    "objectID": "posts/2015-12-22-a-model-of-software-quality-checks.html",
    "href": "posts/2015-12-22-a-model-of-software-quality-checks.html",
    "title": "A Model of Software Quality Checks",
    "section": "",
    "text": "Software quality can be automatically checked by tools like SonarQube, CAST, FindBugs, Coverity, etc. But often these tools encompass several different classes of checks on quality. I propose the following hierarchy to organize these rules."
  },
  {
    "objectID": "posts/2015-12-22-a-model-of-software-quality-checks.html#footnotes",
    "href": "posts/2015-12-22-a-model-of-software-quality-checks.html#footnotes",
    "title": "A Model of Software Quality Checks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m not sure how to ‘noun’ this adjective …↩︎"
  },
  {
    "objectID": "posts/2017-07-17-7principles-docs.html",
    "href": "posts/2017-07-17-7principles-docs.html",
    "title": "Seven Principles of Effective Documentation",
    "section": "",
    "text": "There has recently been more discussion about software documentation (or perhaps that’s because I only see what I’m interested in… hard to say). At any rate, it seems a lot of discussion inevitably breaks down to “what tool will solve my documentation problems” (e.g., this thread). Others have tried to “fix” UML by proposing new modeling approaches (forgetting, perhaps, that the unified modeling language was spurred by exactly this proliferation of diagram notations).\nI don’t think tools, or formats, or templates, or modeling languages, will ever solve the problem you have. But what will help is to put some people in charge of the project who can think clearly and knowledgeably about what exactly is needed. To that end, the most effective advice (yet perhaps least immediately actionable, as compared to “buy X”) are the principles of effective documentation, originally from the Parnas and Clements paper “A Rational Design Process: How and Why to Fake It” 1. Its more concrete form is published in the SEI text “Documenting Software Architectures”, and is part of the introduction to the course we teach.\nThe other “principle” we mention, but is not part of this list, is “if it isn’t needed, don’t do it”. Documentation (good, up to date documentation certainly) has a cost. Only incur that cost if you are going to realize benefit from it (and naturally, the cost is the upfront cost + maintenance cost).\nI think most of the tooling discussions fall from these principles/rules. For example, Daniel Procida gave a presentation on “4 Elements of Successful Docs”, recommends docs have how-to guides, tutorials, discussions, and reference content. This maps to writing for the reader, and recording rationale.\nIn this perspective, a lot of discussions can be better grounded. For example, “avoid ambiguity” motivates the use of something like UML. The UML is useful at least as the “most common” notation people are aware of (and has many many reference books). Using Markdown to keep things current with your build system can help to keep things current. Confluence or other wikis help with organization and avoiding repetition. And so on.\nAs a good researcher, I should mention this topic greatly interests me. If you want to collaborate, get in touch! I think there’s a lot of room for interesting contributions in making documentation better."
  },
  {
    "objectID": "posts/2017-07-17-7principles-docs.html#footnotes",
    "href": "posts/2017-07-17-7principles-docs.html#footnotes",
    "title": "Seven Principles of Effective Documentation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nParnas and Clements, Trans. Software Eng. 12(2), 1986. http://web.engr.oregonstate.edu/~digd/courses/cs361_W15/docs/IEEE86_Parnas_Clement.pdf↩︎"
  },
  {
    "objectID": "posts/2017-05-10-active-learning.html",
    "href": "posts/2017-05-10-active-learning.html",
    "title": "On Active Learning in Software Engineering",
    "section": "",
    "text": "I’ve read 2 papers recently (references) about using active learning to improve classification for software engineering.\nActive Learning is the idea that, if we have a feature space with instances, for the classification task of labeling an instance either “A” or “B”, there are clumps of points that clearly are As, and another clump that are clearly Bs. In between, however, the boundary is unclear. Some instances will be equidistant from both centers of mass, and the classifier will struggle to properly classify it. Active Learning (AL) quite simply picks what are hopefully the “most useful” (for improving the classifier) points for human labeling, which reduces the amount of (possibly) redundant labeling humans have to do (since the labeling time is the most costly part of creating a classifier).\nIt turns out that so far this active learning approach for software data is not too successful. I think there are 2 main reasons.\n1) We don’t have much data. Classifiers do better when they see more instances. In the 2 studies I read, the number of unclassified instances was measured in tens of thousands. Contrast this with most image recognition or information retrieval applications, which have orders of magnitude more training data. In the case of the ImageNet context, they also label substantially more instances (e.g. 150,000 labeled with 10 labels).\n2) More importantly, I think the task is fundamentally difficult. The Borg paper makes this clear; when human raters themselves cannot agree on a label, it probably won’t work any better with active learning. I think this is because some problems have fuzzy label boundaries for non-core feature reasons, while many software concepts are innately (ontologically) unclear. Think about labeling photos of house numbers. I’m pretty confident that any two humans would agree that instance X is a house number. We have clear and simple criteria for what a “number” is (intensionally and extensionally). The reason the classifier struggles is because of non-intensional properties of the data itself: perhaps a tree obscures the top of the 1, or a shadow is partly on the lower digits. In software data, that problem exists as well (e.g. someone talking about an old version of Rails). But for labeling an utterance as technical debt, or a performance bug, or a usability concern, there seem to be broad disagreements on the core discriminating features. If we talk about paradigms like distributed computing, is that an “architectural” discussion? What about a bug that results from not understanding an RPC service?\nWe’ve looked at some of this in our latest research on design rules. We found that while a majority of static analysis/code checker rules can be clearly distinguished as either design or not, there remains this stubborn middle tier that resist easy categorization. We think you can still make progress (after all, these rules may not even fire on your project). But it would be satisfying to have a more repeatable analysis.\n\n\n\nCategorizing rules\n\n\nThe conclusion of the Borg paper really seems useful for future work here. One, they say that the AL approach helps to pull out controversial instances, that then help build rater consensus. Two, using bootstrapping with more positive examples helps the AL improve its accuracy (in other words, there is still benefit to grinding out the labels manually – no free lunch, sorry!).\n\nReferences\n\nN. Van Houdnos, S. Moon, D. French, Brian Lindauer, P. Jansen, J. Carbonell, C. Hines, W. Casey. “Human-Computer Decision Systems for Cybersecurity”, Presentation. https://resources.sei.cmu.edu/asset_files/Presentation/2016_017_001_474277.pdf\nBorg, M., Lennerstad, I., Ros, R., Bjarnasson, E. “On Using Active Learning and Self-Training When Mining Performance Discussions on Stack Overflow”, arXiv:1705.02395v1. Preprint of paper accepted for the Proc. of the 21st International Conference on Evaluation and Assessment in Software Engineering, 2017."
  },
  {
    "objectID": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html",
    "href": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html",
    "title": "Using GitHub for 3rd Year Software Engineering",
    "section": "",
    "text": "This past semester (Winter 2012), I was the instructor for UBC’s CPSC 310: Introduction to Software Engineering. As part of the course, students must complete a large-scale software project in teams of 4–5 in 2 months. This term, I allowed some teams to use GitHub to manage the project."
  },
  {
    "objectID": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html#reasons",
    "href": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html#reasons",
    "title": "Using GitHub for 3rd Year Software Engineering",
    "section": "Reasons",
    "text": "Reasons\nAt UBC, we have for some time used IBM’s Rational Team Concert tool, which is free for academic use, as our software collaboration environment. This was the default tool for this term, as well, save for the three groups who applied to use GitHub. The University of Victoria has been using RTC for a similar purpose.\nRTC is, I’m sure, an excellent product for its intended audience, namely, professional software development teams. It is easy to install and maintain for the technical support staff here, has sufficient documentation, and clients for Mac, Linux and Windows. It is also free for us to use as part of the IBM Academic program. However, in course evaluations, it has been the single most complained-about part of the course. It is cumbersome to install for students, and most importantly, always seems to be out-of-date with other software. In our case, RTC 3 is built using Eclipse 3.4, which is “somewhat” incompatible with the libraries and plugins I was looking to use, chiefly the Google Plugin for Eclipse. A significant amount of course time (TA and instructor office hours) was spent getting RTC to work with the other software for the course. And I am just seeing that IBM is now working on RTC 4, which implies more trouble in the future.\nNow, this is partly because students have not had much experience installing commercial development tools on their machines, and that is certainly a learning objective for this course (I am confident it is a pain point for nearly all software developers, new or otherwise). It is also because students run a bewildering array of operating systems and language profiles on their laptops and desktop computers, which makes support a headache.\nThat being said, my sense was that RTC was simply too much tool for what the students needed. As Greg Wilson’s DrProject experiment showed, students simply do not have time, nor inclination, to leverage the more powerful collaboration aspects. Filling out work items, creating documentation, even committing code is something they just do not see the need for. To get them to try it, we must assign marks to those activities. RTC’s terminology (streams, components, etc) is probably great for a developer with multiple projects: for these students (and me!) it is non-standard with most version control concepts and confusing to use.\nSince I’ve personally used GitHub for a while, and git seems to have a lot of developer mindshare, it seemed like a good fit for an experiment."
  },
  {
    "objectID": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html#experiences",
    "href": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html#experiences",
    "title": "Using GitHub for 3rd Year Software Engineering",
    "section": "Experiences",
    "text": "Experiences\n\nInstructor\nI emailed Github about the use of their web app for education and received a very prompt affirmative. Github will provide an organization account to the instructor, which includes private repositories for up to 200 people. At the end of the semester, they then require you to either delete the repositories (on Github, obviously not locally) or make them public (free accounts).\nThe Github UI is generally simple, but some of the navigation options are confusing from the team manager point of view (me!). Tracking student performance is pretty easy, since you have ready access to the excellent Github website, including issue tracking, change set tracking, pull requests, etc. Github has excellent graphs that allow the instructor team to check who is doing what. There doesn’t appear to be a good way to email all of the students in the various teams at the same time (we are an “organization” made up of 4–5 person teams).\nGit itself is the main reason to use Github. There are vastly superior tutorials on it, and I like the pure distributed model better than what RTC provides. Finally, and perhaps most important, as the instructor I’ve used Git a fair bit and RTC very little. The disadvantages are that there is no central repository for backup purposes, although being distributed this is presumably less important.\n\n\nStudent\nStudents were generally positive. The alternative, in this course, was to use RTC. Git has the advantage of more widespread adoption (you’re unlikely to use RTC at Microsoft, but MSFT supports Git in various places). And of course, if Github goes down, then students can no longer manage issues. Git itself is complex to learn; I should have provided a short tutorial to those teams on the basics of Git.\nThey also found tools like SourceTree and Tortoise invaluable in understanding what was happening with branches and remotes. For a while, a few teams had multiple, non-merged and conflicting branches for each member, which they could resolve once they saw visually how the branches were happening. The concept of remote repositories and pull requests is a little alien at first.\nIssue tracking in Github is primitive relative to RTC. This is a strength for this course, I feel, but when we go from user stories to tasks it means students had to roll their own classification scheme (e.g., define a product backlog item, then the tasks which compose it).\nThe teams which used Github were much stronger than most other teams in the course, so the results are no doubt skewed. That being said, I don’t think RTC was any simpler to use—in a number of teams, at least one team member never managed to commit code to the shared repository."
  },
  {
    "objectID": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html#looking-ahead",
    "href": "posts/2012-04-26-using-github-for-3rd-year-software-engineering.html#looking-ahead",
    "title": "Using GitHub for 3rd Year Software Engineering",
    "section": "Looking ahead",
    "text": "Looking ahead\nThe obvious question is, “Would you use Github again”? The answer is yes, and perhaps even “I would like to make everyone use it.”\nIt was confusing to have two separate tools in the course. Partly, this is because marking is complicated by the fact student teams are in tutorial sections, so some teams in a given tutorial were using Github and some RTC. This meant TAs had to mark both tools (and learn both). Exam questions are more complicated, since you must account for some students never having used RTC, if you ask about issue tracking.\nI like the fact that the project collaboration tool was separate from the IDE. I think RTC’s tight Eclipse integration makes it difficult to install the IDE necessary. Some students ran Eclipse 3.7 in conjunction with RTC (Eclipse 3.4) in order to get plugins working. Since git is so popular, it is much easier to find tool support for it than to munge RTC into your work flow. In future, tools like Mylyn would be useful to better integrate issue tracking into the IDE.\nThe big outstanding issue is privacy. In BC, the provincial government is considering laws that prohibit (or seem to, IANAL) student data being anywhere near a US server (despite students happily sending email about their marks from Hotmail or Gmail). While I respect that motivation, I feel there should be some way to give consent, particularly when so many excellent tools are US-based."
  },
  {
    "objectID": "posts/2016-01-21-the-marginal-utility-of-testingrefactoringthinking.html",
    "href": "posts/2016-01-21-the-marginal-utility-of-testingrefactoringthinking.html",
    "title": "The Marginal Utility of Testing/Refactoring/Thinking",
    "section": "",
    "text": "Andy Zaidman had an interesting presentation about test analytics. The takeaway for me was that a) people overestimate their unit test engineering (estimate: 50%, reality, 25%). But b) the real issue is convincing a developer that this unit test will improve the quality of the code. In other words, like with technical debt, or refactoring, or commenting, the marginal utility of adding a test is perceived to be low (and of course the cost is seen as high). Each new individual test adds nothing to the immediate benefit (with some exceptions if one is following strict TDD). And yet each one requires switching from the mental model of the program to the one of Junit frameworks and test harnesses.\nThe issue is not whether testing is good or bad, but rather, which testing is most useful. It seems unlikely to me that the value of individual tests is normally distributed but rather power-law form (i.e., that there are a very few extremely high value tests). And this isn’t just about testing; indeed, most activities with delayed payoff—refactoring, documenting, architecting—likely exhibit the same problem. It is hard to convince people to invest in such activities without giving them concrete proof it is valuable. You just have to look at the default examples for Cucumber, for instance, to see that the vast majority are trivial and easily grasped without any of the tests. Similarly, “code smells are bad”, but bad might just mean they look nasty, while having little to do with the underlying effectiveness of the code. It isn’t technical debt if it never causes a problem. It isn’t a bug if it isn’t worth fixing it.\nIn new work we are starting with Tim Menzies, we are trying to understand the inflection point beyond which your decisions add little incremental value (i.e., stop adding more tests). The good news is this is easy to spot in hindsight; the challenge is to take those lessons and determine this before doing hours of pointless work. The direction we are taking is to try and capture the common patterns the key decisions share (in the testing example, perhaps this is bounds testing). Ultimately, we hope to provide advice to developers as to when the marginal utility falls below a threshold (i.e., stop testing!)\nThe other point is the over-reliance of software engineering on hoary folklore. Things like “some developers are 10x as productive”, or “80% of bugs occur in requirements”, tend to be statements that are derived from a single study, conducted in 1985, on 3 large scale defense projects, but have somehow made their way down the years to become canon. Ours is not the only field to suffer from this, of course. But when capable developers refuse to pay 200$ a year to join the IEEE Digital Library, it seems to demonstrate a firm commitment to ignorance."
  },
  {
    "objectID": "posts/2017-05-11-visual-abs.html",
    "href": "posts/2017-05-11-visual-abs.html",
    "title": "Visual Abstract attempt",
    "section": "",
    "text": "In response to Greg Wilson’s challenge, I did a quick attempt at a Visual Abstract for a recent paper.\n\n\n\nVisual Abstract: Identifying Design Rules in Static Analysis Tools. Evaluated 464 rules, 19% design related, 67% easy to classify.\n\n\nI think it turned out ok; it captures the core findings and presumably will prompt people to look at the paper. I’ve attached the Keynote slide I used in a repo on Github.\nA few comments:\n\nGraphic design is a skill you need to work on (duh). Even with this template, I don’t think it is super compelling. I just used out of the box icons.\nThe footer kinda loses relevance when you don’t have a big name JOURNAL behind you. Something else can go there. I used the conference logo, but maybe some logo for your lab.\nI wanted a URL to point to the full paper, but a bar code might be better. If anyone uses that anymore.\nFor qualitative papers, and maybe software engineering in general, the “outcome data” at the bottom is more difficult to come up with. I don’t know if I can easily pull three nuggets of improvement for each paper (but I hear Greg’s baritone susurration saying “well yes, that’s part of the problem”)\nAs someone on Twitter pointed out, these are intrinsically visual and thus not accessible to the visually impaired. I do think they help the “academicese-impaired”, but each time one of these is used, I would hope a non-visual summary is also presented. Pulling the text together shouldn’t be too hard. I’ve had a go in the “alt” text above.\nDoing a whole batch of these (say for an ICSE track) would be a fair bit of work. Presumably you could pick papers you’ve had to read anyway (and cared about). But summarizing the contributions is not so simple (for me, anyway). Again, perhaps that points to a wider problem.\n\nI’ve noticed more and more papers calling out contributions in special boxes, and bulleted lists in the introduction. I think this is great. One of my pet peeves is a reviewer who points out some trivial English error, but tolerates the total incoherence of the introduction.\nRelated to this is a visual portrayal of the methodology. This happens a lot in medicine, where lots of experiments are conducted and explaining complex cross-over designs is important. But you can see a similar example in Borg et al. 2017, below:\n\n\n\nSample workflow cartoon\n\n\nThis explains how the study was conducted. Again, anything that can explain what is going on for a busy reviewer is helpful. Remember, in 2017 FSE reviewers seem to have reviewed 25-28 papers each. Expecting them to spend more than 30-45 minutes on each one is unrealistic. So make your time with them count!"
  },
  {
    "objectID": "posts/2012-12-19-a-stitch-in-time.html",
    "href": "posts/2012-12-19-a-stitch-in-time.html",
    "title": "A stitch in time…",
    "section": "",
    "text": "This blog post from the excellent complexity blog Godel’s Lost Letter is on the theory behind branch and bound search. One of my favourite things about this sort of analysis is how it it can eliminate, with mathematical certainty, hours and hours of programming effort. Consider this statement:\n\nThere is an issue of being odd or even, which matters but not hugely, since pruning the bottom layer is not so valuable.\n\nI have spent many hours working on problems that might fall into the “matters, but is not so valuable” category. A few hours of analysis might well have saved me a lot of trouble."
  },
  {
    "objectID": "posts/2019-05-17-job-search-canada.html",
    "href": "posts/2019-05-17-job-search-canada.html",
    "title": "Academic Job Searches—A Canadian Perspective",
    "section": "",
    "text": "Academic job interview season is wrapping up, so I thought I’d capture the process from the Canada point of view.\nAcademic CS jobs in Canada follow mostly the same pattern and process as the US (here I am talking about research-focused, tenure-track roles). Hence I think most of the advice from Philip Guo, and Wes Weimer and his academic offspring, are totally applicable (and indeed, were what I relied on in my search). There are a few subtleties I think are useful for applicants to know. Disclaimer: I am relatively junior, and only have limited experience applying in Canada, so these insights are based on my limited sample and from talking to colleagues here. I am also not a legal or immigration expert, so I make no warranty about this advice.\n\nUnderstand why you are interested in Canada\nIn the Weimer/Le Goues job seeker’s guide, they make the point that US candidates tend not to move to Canada. I think it is safe to say that if you have spent your entire master’s/PhD in the States, you have worked in the NSF/DARPA/DOD model of funding, and have family ties there, then the switch to Canada would be a big change. I think this is especially true for smaller schools like ours. We’re a small place but proud (both Canada and Victoria!). So make it clear in your cover letter or interview why you would come. Hopefully reading this guide will help!\n\n\nExplain/communicate the proposed Discovery grant you would win\nIn Canada funding is fairly different than the US. For one thing, Canadian schools have substantially lower tuition for grad students (although that is changing). Faculty research budgets have much lower student stipends as a result, and the grant sizes reflect that. A moderate US grant might be 100k/year; in Canada that would be equivalent to 20k, but support the same research program.\nYour application and interviews should demonstrate you understand this. I suggest reading up at the NSERC page, and also the research services page for the university you apply to.\nThe main grant for new faculty is the Discovery grant. It is a five year grant worth from $20k-50k a year. You are evaluated equally on your ability/experience with highly qualified personnel; your personal ability as a researcher (i.e. CV); and the research proposal. Not holding a Discovery grant is a problem because getting other federal funding depends on this, to some extent. The good news, especially for ECR, is that success rates are relatively high (60-75%). You can expect to prepare this the summer you get hired, for submission by Nov 1.\nYour job talk and your research statement should outline some elements of the five page grant proposal you would write. Departments want to see what you would propose, and how able you are to communicate your vision to external readers. It is a 5 year program, so scope your “future work” to that time frame.\nI think this is broader advice than Canada-only, but one thing I’ve noticed is that applicants who are just finishing a PhD give more narrowly focused talks. Two things to keep in mind if this describes you. 1. You will be competing with people who have 2-4 years of post-doctoral training, and a corresponding breadth of research, more experience training students. Stretch your talk to show how you have the potential to succeed like that. Conversely, one question about post-docs is often “how independent can they be”. This is particularly true if you come from a big lab with a famous PI. 2. Think like a professor. What grant areas will you target? How would you manage 5 masters/phd students? How will you balance teaching load with research? I don’t think you need to feel uncompetitive: we invited you for a reason. But the onsite interview is when we want to see if you are ready for what can be is a very demanding job.\n\n\nFunding\nEngagement with industry The federal government has been a big supporter of industry partnerships recently, although the programs were recently overhauled. This typically means that if you have an industry partner with skin in the game, i.e. financial assistance, you have an excellent chance of obtaining government matching funds. Conversely, if you prefer pure research with no immediate outcomes, finding funds might be more difficult. There are very few large granting agencies. There is no equivalent to DARPA/IARPA, DHS, DOD, DOE funding in Canada; those projects would work with specific people at specific agencies to secure one-off funding. In BC, nearly all grants would come via NSERC programs, or MITACS matching. There are also Networks Centres of Excellence such as MEOPAR that allocate funds in targeted areas (these are being phased out). There is also a recent Defence initiative, IDEaS, to increase Canadian funding for research with defence applications. Finally, there were industry-led superclusters announced, but who/what gets funding is still very unclear. It seems to focus mostly on subsidies for industry-led research.\nIn general, I would say finding funding is much more individualized and distributed than in the States. There are plenty of places to find adequate funding (again, a student probably only costs 20-25k a year), but how to get it is much less clear than a DARPA BAA program. A cynic might say this is because funding announcements are more closely tied to electioneering.\nSummer students and internships. We have a similar program to the REU approach, called USRAs. These are government matching for student research semesters. Again, these are allocated on a per-institution basis (bigger places get more).\nWe have an excellent grid/HPC/cloud computing infrastructure, ComputeCanada. They conduct yearly resource allocation competitions. I don’t know what the success rates are.\nFor large infrastructure, e.g., robots, 3d printers, tabletop displays, quantum computers, the Canadian Foundation for Innovation holds annual competitions for this, but success rates are fairly low.\n\n\nTenure\nWell, more to come from me on this one, but my general sense is that tenure is more collaborative and mentoring than many US places. I don’t think there is the equivalent of “didn’t get the NSF grant, didn’t get tenure”, or “didn’t get 1 million in funding, didn’t get tenure”. That said, standards are just as high as US Tier 1 schools; we just want to help you achieve them. We’re friendly, eh?\n\n\nSpecialty hiring\nCRCs. You may be in the enviable position of applying for a Canada Research Chair. These are a nationwide funding mechanism for research positions. We have Tier 1 (7 years, renewable, senior) and Tier 2 (5 years, renewable, junior/emerging). They typically come with higher salary and teaching relief. Each university gets a quota from the federal government. The approval process is a bit more involved. In addition to approval from (department-faculty/dean-VP academic/provost), you will have your application submitted to the federal government, wherein the case will be made that you are uniquely qualified, amazing, etc. This is almost never turned down, from what I can tell, but could be. In particular, the federal government has a strong desire to see equal allocations of these CRCs to male and female candidates.\n\n\nRequirement for hiring Canadians\nDepartments are usually required to prefer Canadians over non-Canadians, for immigration purposes. This means that of two totally equivalent candidates, the Canadian citizen or permanent resident would be made an offer. If you are a PR/citizen, or applying for PR, that is worth highlighting somewhere.\n\n\nImmigration is easy\nI can’t speak from experience, but my understanding is that immigration to Canada as a permanent resident, and eventual citizenship, is much easier than the US process (with which I do have experience). This is also true for immediate family (spouse/children). In some cases, permanent residency is possible in months, not years.\n\n\nSalary and benefits\nIn general Canada pays less salary. Keep in mind that it is a 1 year salary, not 9 months. Most Canadian schools don’t have the concept of a summer salary. At UVic, we operate on 3 equal semesters, and allocate a research semester where you would like (subject to teaching needs of course).\nThe CRA survey has more useful information. Health care is provincially funded from your taxes, so don’t expect to lose 500-600$ a month to health premiums. From working in the US, even being a well-paid employee at a great employer, there was a significant cost (mental and financial) in understanding yearly plan changes—even without chronic conditions.\nIn most places, faculty are unionized or quasi-unionized. This means you fall into a grid, and your salary increases will be based on a formula in the collective agreement. You can probably look this up online for each institution you visit. Hint: you want to move up the grid as much as possible before you start the job. So Prof. Le Goues’s advice on startup over salary might change, since your salary will be the baseline for future percentage increases.\n\n\nSummary\nI would sum up by saying Canada is an awesome place to do research, and I hope you apply to Canadian universities! Especially mine!\n\n\nResources\n\nMaclean’s Guide to Canadian Universities: This is the Canadian equivalent (in all respects, good and bad) to US News and World Report. It divides universities into medical/doctoral, comprehensive, and primarily undergrad. Canada does not have the same diversity of higher education as the US—for example, there are few private institutions here. The main division for research is whether the school has a medical school or not, as med schools are tightly controlled (public health care dictates number of seats), and med schools tend to accumulate massive amounts of research funding. My school is categorized as a comprehensive, but I wouldn’t say this equates to “more teaching”.\nNSERC: The main engineering funding body, similar to NSF.\nTaulbee Survey: Various stats on academic CS jobs, including some from Canada."
  },
  {
    "objectID": "posts/2013-05-23-some-advice-on-doing-a-postdoc-in-software-engineering.html",
    "href": "posts/2013-05-23-some-advice-on-doing-a-postdoc-in-software-engineering.html",
    "title": "Some Advice on Doing a PostDoc in Software Engineering",
    "section": "",
    "text": "Post-doc positions in CS are a growing part of the research landscape, as seen in this figure from the CRA:\n[caption id=“” align=“alignnone” width=“445”][](http://www.cccblog.org/wp-content/uploads/2011/05/figure21.png) CRA 2011 Research positions[/caption]\nSo if you are a senior doctoral student, should you take a post-doc offering? Herewith a few tips based on my own experience (7 year doctoral student in Toronto, 1.5 years postdoc at UBC, now with SEI as researcher).\n\nFigure out your long-term goal. Do you want a research intensive faculty post? Or a teaching-intensive job? Industrial research lab? Industry development job? I would not bother with a post-doc if I wanted a programming job (even a PHD is a hindrance here, in most cases).\nThink about networking. Most of the people who get the top jobs in the field are well-connected to the main community, via supervisor connections, industry internships, collaborations. You will need to secure 3-4 people who will write highly of you. You need to get onto the short list. I am assuming you already understand what the bar is for high quality research.\nAvoid teaching positions if you want to do research, and vice-versa. I did a dual position, and while I love teaching, research suffered. There is plenty of time to think about teaching later, and in my experience, top research schools almost never ask about teaching experience. On the other hand, if you apply to teaching universities, then demonstrable ability to manage a large class should serve you well, as will good evaluations.\nEvaluate how well the position will accommodate your existing research contributions. You simply do not have time in the standard 2 year postdoc to shift your research interests dramatically. To me this is one big difference with life science postdocs, where you get lab experience and the positions are typically for 3-4 years. Ideally, you will be able to submit to ICSE, CAV, FMCAD, PLDI etc. immediately after starting. I’m not convinced that hiring committees are at all sympathetic to any gaps in your publication record.\nBe realistic about the quality of the lab’s past research. Are they publishing in the top venues? Is there a history of collaborative work, where you might be able to tail along on a paper as you start your post?\nFinally, all the other criteria: is it a nice city? Are the people friendly? What is the salary? 50K Canadian is at the upper end for most positions.\n\nThese tips are mainly pragmatic and from a research hiring point of view, where the main reason to do a post-doc is to improve your publication record and increase your social network. That being said, one of the things I most liked about my postdoc was meeting and working with great people. That sticks with you longer than any paper submissions will.\nEDIT: I’ve been reminded of another criterion, namely, does your partner (if any) support your decision!"
  },
  {
    "objectID": "posts/2014-07-24-cults-of-personality-and-software-process-improvement-2.html",
    "href": "posts/2014-07-24-cults-of-personality-and-software-process-improvement-2.html",
    "title": "Cults of Personality and Software Process Improvement",
    "section": "",
    "text": "I’m a fan of the Cynefin framework. I find it a great tool for understanding what type of problem you are trying to solve. The notion of complex/complicated/simple is quite helpful. You could do worse then to read Dave Snowden’s blog, as he explores each of the domains in the context (most often) of software projects.\nRecently Mr Snowden has been critiquing the Scaled Agile Framework (SAFe) put together by Dean Leffingwell. This attack on SAFe is not unprecedented. It’s hard to take attacks like this too seriously when their proponents don’t put forth data, but merely theory.\nOne of the most difficult parts of doing research in Software Engineering is its inherently uncontrollable, one-off nature. Sure, in some cases—like websites for restaurants, for example—we see repeatability. But the most interesting projects, the ones SAFe is applied to, the complex or perhaps complicated ones, there is no repeatability (by definition). This makes it impossible to say with any degree of accuracy what factors are contributing to the success or failure of the project.1\nIn particular, when you have strong, intelligent, experienced consultants like Mr Snowden, or Mr Leffingwell, or various other graybeards, I don’t think you can control for the ‘personality’ factor. That is, what portion of the success of the initiative (say, applying Sensemaker or SAFe or Scrumban or what have you) is due to the tool/process improvement/methodology, and what portion is due to the smart person effect of the consultant? This is made more difficult when that consultant has a very strong economic incentive to point to the methodology as the distinction, since their business is inextricably tied together with that methodology. Furthermore, just the fact that a company has reached out for help indicates some level of self-awareness.\nMy feeling is that given a successful team, led by an enlightened manager, it wouldn’t matter what methodology they used (which I mentioned previously in the context of tools). And there is some evidence to support this: Capers Jones suggests RUP and TSP have higher quality than Scrum or other approaches. Now that is just one dataset, but it is exactly one more than Mr Snowden has produced, as far as I can tell (the plural of anecdote is not data).\nDoes all this mean it doesn’t matter if we choose RUP, SAFe, Scrum, Kanban, Six Sigma, or Sensemaker? To some extent, I think that is true. I would guess that your measurable outcomes after implementing TSP would be similar to the outcomes after implementing SAFe. But the point is, one cannot measure these things in isolation! You will never know (Heisenberg-like) whether something else would have been better. The local project context is so important that the principles are more important than the specific practices (e.g., the agile manifesto, Cynefin domains, good organizational practices, etc)."
  },
  {
    "objectID": "posts/2014-07-24-cults-of-personality-and-software-process-improvement-2.html#footnotes",
    "href": "posts/2014-07-24-cults-of-personality-and-software-process-improvement-2.html#footnotes",
    "title": "Cults of Personality and Software Process Improvement",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWith one exception I am aware of: this paper from Simula in Norway. They paid 4 different companies to develop to the same set of requirements in order to understand the maintainability characteristics of different approaches. But even there, the results are difficult to generalize. Anda, B.C.D.; Sjoberg, D.; Mockus, A, “Variability and Reproducibility in Software Engineering: A Study of Four Companies that Developed the Same System,” IEEE Transactions on Software Engineering, vol.35, no.3, pp.407,429, May-June 2009 doi: 10.1109/TSE.2008.89 ↩︎↩︎"
  },
  {
    "objectID": "posts/2016-04-22-on-scams-new-engineering-track.html",
    "href": "posts/2016-04-22-on-scams-new-engineering-track.html",
    "title": "On SCAM’s new “Engineering Track”",
    "section": "",
    "text": "This year SCAM, the Working Conference on Source Code Analysis and Manipulation (located in Raleigh, NC, Oct 2–3 2016) includes an engineering track, as described here. The CFP is available here. This track will be co-chaired by myself and Jurgen Vinju. In this post I want to briefly explain what an engineering track is and why you should submit to it! 1"
  },
  {
    "objectID": "posts/2016-04-22-on-scams-new-engineering-track.html#footnotes",
    "href": "posts/2016-04-22-on-scams-new-engineering-track.html#footnotes",
    "title": "On SCAM’s new “Engineering Track”",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIncidentally, I agree with and support the ICSME co-chairs’ statement on the anti-LGBT legislation in North Carolina.↩︎\nThat definition is from Roel Wieringa’s excellent design science book.↩︎\ncan itches be unknown? I may be mixing metaphors.↩︎\nIncidentally, I am not a big fan of the term “industry” or “industrial”. Maybe it is my location in Pittsburgh, but it conjures up steel mills and heavy machinery. The other problem is the term “industry” is used as a catch-all for a widely different set of folks, from a 2 person startup to a Fortune 500 company or DOD agency. I prefer research vs practice. Not a huge fan of “real-world” either, since we all live in the real world. Presumably.↩︎"
  },
  {
    "objectID": "present.html",
    "href": "present.html",
    "title": "Presentations",
    "section": "",
    "text": "Most of my talks can be found at Slideshare or more recently, SpeakerDeck.\nRecordings: * Technical Debt (TD): Tools + Techniques for Identifying, Fixing, and Managing TD in Research S/W”. A talk at the Canada Research Software conference (CANARIE). July 2021.\n\nMatrix talk from October, 2018: When Writing it Down is Not Enough: the Era of Computational Notebooks\nMatt’s talk on VAEs"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neil Ernst",
    "section": "",
    "text": "I am associate professor of Computer Science at the University of Victoria.\nYou can learn more about my research. Download my short bio.\nI teach courses in software engineering (mostly) for our Software Engineering and Computer Science programs.\nI serve in various roles as workshop and conference organizer, program committees, student supervision, journal reviews, etc. Among others:\n\nSenior Associate editor, Journal of Systems and Software\nregistered reports and open science advocate\nprogram committees - in the past, ICSE, RE, XP, CAISE, ER, MODELS\nAssociate Editor, Journal of Empirical Software Engineering\nchief wrangler, RoPES workshop on recruitment\n\n \n  \n   \n  \n    \n     Mastodon\n  \n  \n    \n     Github"
  },
  {
    "objectID": "index.html#consulting",
    "href": "index.html#consulting",
    "title": "Neil Ernst",
    "section": "Consulting",
    "text": "Consulting\nI occasionally act as speaker, consultant and expert for matters relating to software architecture and software requirements, including architecture analysis, modern software development practices, and analytics for software engineering."
  },
  {
    "objectID": "index.html#previously",
    "href": "index.html#previously",
    "title": "Neil Ernst",
    "section": "Previously",
    "text": "Previously\n\n\nsenior member of the technical staff at the Software Engineering Institute at Carnegie Mellon University.\npostdoc in software engineering at the University of British Columbia.\nPhD student in Computer Science at the University of Toronto.\nmaster’s student in Computer Science at the University of Victoria.\nundergraduate research in geography and GIS at the University of Victoria, including work placements with the BC Ministry of the Environment."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Neil Ernst",
    "section": "Contact",
    "text": "Contact\nPhone: c’mon man email: see bottom Fax: 250-472-5708 Postal Mail: Department of Computer Science University of Victoria Engineering & Computer Science Building (ECS), Room 504 PO Box 1700 STN CSC Victoria BC V8W 2Y2 Canada"
  },
  {
    "objectID": "students.html",
    "href": "students.html",
    "title": "Students",
    "section": "",
    "text": "One of the best parts of being a prof is working with talented and passionate graduate and undergraduate students. We have a research group page at the Octera Github site. I collaborate with my own students, but also with other students, with other groups and faculty (like CHISEL and SEGAL), and industry.\nProspective graduate students see here.\nCurrent students should read through the onboarding documents."
  },
  {
    "objectID": "students.html#students",
    "href": "students.html#students",
    "title": "Students",
    "section": "Students",
    "text": "Students\nSee the up to date list at Github"
  },
  {
    "objectID": "prospective.html",
    "href": "prospective.html",
    "title": "Prospective Students",
    "section": "",
    "text": "Do you want to do your Master’s or PhD with me?1\nYou will first need to apply to and be accepted by the University of Victoria. If you are applying for an NSERC or equivalent scholarship/fellowship, please feel free to contact me first.\nYour interests and skills should have some (a lot) of overlap with what I do. For more on that, see my research page, or my blog, or Google Scholar. In general, if you care about software, putting software together, making sure software does what we want, we can probably sort something out.\nWhat will you get out of it? You will be trained in how to conduct research, how to write and communicate your ideas to others, including industry practitioners; you will write software; you will help push forward the boundaries of knowledge in software research. It’s an exciting time to be in research!\nEmail me:\nFor potential MSc students: If you acquired research experience during your undergraduate degree, please tell me about it. Publications in respected conferences or international journals, an undergrad thesis, a Capstone project, an undergrad research assistant position or a directed studies project make you a stronger candidate.\nFor potential PhD students: Tell me about your previous graduate work and include PDFs of your thesis and your best and most recent publications. PhD applicants should have a strong background in computer science or software engineering research (or a related field).\nThank you for your interest in working with me. I receive many emails from prospective students and providing me with all of the requested information will help your email stand out!"
  },
  {
    "objectID": "prospective.html#footnotes",
    "href": "prospective.html#footnotes",
    "title": "Prospective Students",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCribbed largely from the CHISEL group page↩︎"
  },
  {
    "objectID": "geomatics_497.html",
    "href": "geomatics_497.html",
    "title": "Geomatics 497",
    "section": "",
    "text": "One of the requirements of our combined program in Geomatics (of which I am the CS advisor) is to do a capstone project (directed studies) on a geomatics topic.\nThe idea is you undertake a directed studies on a combined geomatics topic of your choice, working with a supervisor in either Geography or CS. The topic should cover CS and Geography concepts.\nPast work has looked at ML algorithms for land surface classification, sea ice thickness prediction with VAEs, disease modeling, etc.\nUsually the directed studies structure - lit review (20%) - weekly reports/updates (20%) - interim report (20%) - final report (30%) - final seminar presentation (10%) (mandatory)\nThe final report is usually around 8-10 pages. The course effort should be appropriate for 1.5 units of work.\nTo find a supervisor, you can talk to a prof working in an area you really liked, or you can chat with me and I can suggest some names or projects.\nIf you are really passionate about orcas, for example, you can work with the Whale Lab. If you loved numerical analysis, then you can work on approximation methods for convex optimization. The only trick is to make sure you have elements of both geography (where are whales feeding) and CS (answered by constructing a neural network, doing data processing, etc.)."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "The PI as COO\n\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n  \n\n\n\n\nThe Scientific Method 2021 edition\n\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2021\n\n\n\n\n\n\n  \n\n\n\n\nOn Bots in Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2021\n\n\nNeil Ernst\n\n\n\n\n\n\n  \n\n\n\n\nREFSQ Panel session on Open Data and RE Education\n\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2021\n\n\n\n\n\n\n  \n\n\n\n\nThe Triumvirate of Teaching and Work Life Balance\n\n\n\n\n\n\n\nteaching\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2021\n\n\n\n\n\n\n  \n\n\n\n\nRunning a Mining Challenge Using Kaggle\n\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2020\n\n\n\n\n\n\n  \n\n\n\n\nAcademic Job Searches—A Canadian Perspective\n\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2019\n\n\n\n\n\n\n  \n\n\n\n\nBayesian Hierarchical Modeling in Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSeven Principles of Effective Documentation\n\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2017\n\n\n\n\n\n\n  \n\n\n\n\nMoving to UVic\n\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2017\n\n\n\n\n\n\n  \n\n\n\n\nVisual Abstract attempt\n\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2017\n\n\n\n\n\n\n  \n\n\n\n\nOn Active Learning in Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2017\n\n\n\n\n\n\n  \n\n\n\n\nThoughts on Amy Ko’s “PL as …” keynote\n\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2016\n\n\n\n\n\n\n  \n\n\n\n\nDay Hikes\n\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2016\n\n\n\n\n\n\n  \n\n\n\n\nColumbus’s Heilmeyer Catechism\n\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2016\n\n\n\n\n\n\n  \n\n\n\n\nOn SCAM’s new “Engineering Track”\n\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2016\n\n\n\n\n\n\n  \n\n\n\n\nOn Using Open Data in Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nMar 7, 2016\n\n\n\n\n\n\n  \n\n\n\n\nThe Marginal Utility of Testing/Refactoring/Thinking\n\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2016\n\n\n\n\n\n\n  \n\n\n\n\nA Model of Software Quality Checks\n\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRequirements, Agile, and Finding Errors\n\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2015\n\n\n\n\n\n\n  \n\n\n\n\nHow Writing Code is Like Making Steel\n\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGarbage In, Garbage Out\n\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRunning a “Critical Research Review” at #RE15\n\n\n\n\n\n\n\n\n\n\n\n\nAug 25, 2015\n\n\n\n\n\n\n  \n\n\n\n\nA Field Study of Technical Debt\n\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2015\n\n\n\n\n\n\n  \n\n\n\n\nThoughts from a CodeFest\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2015\n\n\n\n\n\n\n  \n\n\n\n\nFrameworks, libraries, and dependencies\n\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2015\n\n\n\n\n\n\n  \n\n\n\n\nThe Gap Between User Requirements and Software Capabilities as Technical Debt\n\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2015\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring programmer productivity is futile.\n\n\n\n\n\n\n\n\n\n\n\n\nJan 6, 2015\n\n\n\n\n\n\n  \n\n\n\n\nCults of Personality and Software Process Improvement\n\n\n\n\n\n\n\n\n\n\n\n\nJul 24, 2014\n\n\n\n\n\n\n  \n\n\n\n\nSoftware research shouldn’t be about the tools\n\n\n\n\n\n\n\ncomplexity\n\n\nIT\n\n\nsemantic web\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2014\n\n\n\n\n\n\n  \n\n\n\n\nEvidence in Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2013\n\n\n\n\n\n\n  \n\n\n\n\nConfiguring SONAR with Maven on Mac\n\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2013\n\n\n\n\n\n\n  \n\n\n\n\nThe Circle, a novel\n\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2013\n\n\n\n\n\n\n  \n\n\n\n\n13 Great Software Architecture Papers\n\n\n\n\n\n\n\n\n\n\n\n\nSep 24, 2013\n\n\n\n\n\n\n  \n\n\n\n\nVirtual Conferences\n\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2013\n\n\n\n\n\n\n  \n\n\n\n\nKnowledge and complexity\n\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2013\n\n\n\n\n\n\n  \n\n\n\n\nSome Advice on Doing a PostDoc in Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2013\n\n\n\n\n\n\n  \n\n\n\n\nThe fuzzy notion of “business value”\n\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2013\n\n\n\n\n\n\n  \n\n\n\n\nObtaining a Pennsylvania Driver’s Licence with an H1-B\n\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2013\n\n\n\n\n\n\n  \n\n\n\n\nTeaching Advanced Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nJan 25, 2013\n\n\n\n\n\n\n  \n\n\n\n\nA stitch in time…\n\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2012\n\n\n\n\n\n\n  \n\n\n\n\nUsing GitHub for 3rd Year Software Engineering\n\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2012\n\n\n\n\n\n\n  \n\n\n\n\nWhat I learned at UofT\n\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2011\n\n\n\n\n\n\n  \n\n\n\n\nWriting Complex Latex Documents with Scrivener 2.1 and MultiMarkDown 3\n\n\n\n\n\n\n\nmmd3\n\n\nscrivener\n\n\nthesis\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2011\n\n\n\n\n\n\n  \n\n\n\n\nShould we care about evidence-based software engineering?\n\n\n\n\n\n\n\ntest\n\n\nevidence\n\n\nsoftware\n\n\ntheory\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2010\n\n\n\n\n\n\nNo matching items"
  }
]